{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Password:  ·······\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import miniupnpc\n",
    "from pyproj import Proj, transform\n",
    "from fabric import Connection\n",
    "\n",
    "#adding prognos tools\n",
    "sys.path.insert(0, \"/home/jose-luis/Envs/niva_prognos/PROGNOS/\")\n",
    "from prognos_tools.encrypt import decryptString,encryptString\n",
    "from prognos_tools.Basin_fabric2 import Basin\n",
    "\n",
    "import psycopg2\n",
    "import getpass\n",
    "import gmaps\n",
    "\n",
    "gmapsToken=b'gAAAAABctxJp5wE73qK6U5VieCi0WXNnNex4KxLZHutsESa8fW9v43lLa1Ag0qsxKFjXXo9MBAdvUpqJPW-QmCE0gH_Opf9g4xAG1VaI2WarO_xDZg44VLMCHkd_6O8ofgp8u4VuFBMr'\n",
    "key = getpass.getpass('Password: ')\n",
    "apiKey = decryptString(gmapsToken,key)\n",
    "gmaps.configure(api_key=apiKey)\n",
    "del key,apiKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of database containing processed dem for catchment delineation\n",
    "## Creation of virtual machine with postgresql, postgis and plpgsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudInfo = {'project'      : 'nivacatchment',\n",
    "             'zone'         : 'europe-west3-a',\n",
    "             'instanceType' : \"n1-highmem-16\",\n",
    "             'instanceName' : \"svalbard\",\n",
    "             'image'        : 'debian-9-stretch-v20190423',\n",
    "             'imageProject' : 'debian-cloud',\n",
    "             'diskSize'     : '200',\n",
    "             'username'     : \"jose-luis\",\n",
    "             'keyDir'       : './'\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "instantiationDict= {\n",
    "  \"machineType\" : \"zones/{}/machineTypes/{}\".format(cloudInfo['zone'],cloudInfo['instanceType']),\n",
    "  \"name\" : cloudInfo['instanceName'],\n",
    "  \"canIpForward\": \"false\",\n",
    "  \"networkInterfaces\": [\n",
    "     {\n",
    "       \"subnetwork\": \"projects/{}/regions/{}/subnetworks/default\".format(cloudInfo['project'], '-'.join(cloudInfo['zone'].split('-')[:-1]) ),\n",
    "       \"accessConfigs\": [\n",
    "        {\n",
    "          \"kind\": \"compute#networkInterface\",\n",
    "          \"name\": \"External NAT\",\n",
    "          \"type\": \"ONE_TO_ONE_NAT\",\n",
    "          \"networkTier\": \"PREMIUM\"\n",
    "        }\n",
    "       ]     \n",
    "     }\n",
    "     ],\n",
    "    \n",
    " \"tags\": {\n",
    "    \"items\": [\n",
    "      \"http-server\",\"https-server\",\"postgres\",\"ssh\"\n",
    "    ]\n",
    "  },\n",
    "  \"disks\": [\n",
    "    {\n",
    "      \"boot\": True,\n",
    "      \"autoDelete\": True,\n",
    "      \"deviceName\": cloudInfo['instanceName'],\n",
    "      \"initializeParams\": {\n",
    "        \"sourceImage\": \"projects/debian-cloud/global/images/debian-9-stretch-v20191014\",\n",
    "#         \"diskType\": \"projects/{}/zones/{}/diskTypes/pd-standard\".format(gce.project,gce.zone),\n",
    "         \"diskSizeGb\": cloudInfo['diskSize']\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"items\": [\n",
    "      {\n",
    "       \"key\": \"ssh-keys\",\n",
    "       \"value\": \"dummy\"\n",
    "      },\n",
    "      {\n",
    "       \"key\": \"startup-script\",\n",
    "       \"value\": '''#!/bin/bash\n",
    "sudo apt-get update\n",
    "yes | sudo apt-get install postgresql postgresql-contrib postgis postgresql-server-dev-all unzip git cmake g++ gcc libopenmpi-dev gdal-bin libgdal-dev python-gdal libfftw3-dev htop grass grass-dev libgdal-grass saga\n",
    "\n",
    "export GCSFUSE_REPO=gcsfuse-`lsb_release -c -s`\n",
    "echo \"deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
    "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "yes | sudo apt-get update\n",
    "yes | sudo apt-get install gcsfuse\n",
    "\n",
    "'''\n",
    "      },\n",
    "    ]\n",
    "  } \n",
    "}\n",
    "\n",
    "\n",
    "# \"initializeParams\": {\n",
    "#        \"sourceImage\": \"projects/debian-cloud/global/images/debian-9-stretch-v20191014\",\n",
    "#        \"diskType\": \"projects/nivacatchment/zones/us-central1-a/diskTypes/pd-standard\",\n",
    "#        \"diskSizeGb\": \"10\"\n",
    "#      },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oct 29 12:34:33 svalbard systemd[1]: Startup finished in 2.096s (kernel) + 2min 10.853s (userspace) = 2min 12.950s.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'34.89.150.135'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vm characteristics\n",
    "basin=Basin('/home/jose-luis/Envs/gce_framework/code/keys/nivacatchment.json',cloudInfo)\n",
    "display(basin.properties)\n",
    "\n",
    "info = basin.get('projectInfo')\n",
    "display('Can now talk to project {}'.format(info['name']))\n",
    "\n",
    "\n",
    "#Setting ssh firewall for project\n",
    "inOffice = True\n",
    "if not inOffice:    \n",
    "    with Connection('localhost') as c:\n",
    "        hubIp = c.local('curl https://ipinfo.io/ip').stdout.strip()\n",
    "        basin.setSSHPort(hubIp,inOffice=False)\n",
    "        basin.setPostgresAccess(hubIp,inOffice=False)\n",
    "else:\n",
    "    basin.setSSHPort()\n",
    "    basin.setPostgresAccess()\n",
    "    \n",
    "#Actually instantiating the machine\n",
    "ip=basin.instantiate(wait=True,ownDict=True,inst=instantiationDict) #wait until the vm is actually up and running\n",
    "display(ip)\n",
    "\n",
    "#Allowing local connections on the VM without password by modifying the pg_hba.conf file\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                user=basin.properties['username'],\n",
    "                connect_kwargs={\"key_filename\": basin.properties['keyFile'],}\n",
    "                ) as c:\n",
    "    c.sudo('''find /etc -name pg_hba.conf -exec sed -i 's|\\(^host \\+all \\+all \\+::1/128 \\+\\).*|\\\\1trust|g' {} \\; ''')\n",
    "    c.sudo(\"service postgresql restart\")\n",
    "\n",
    "\n",
    "#Defining custom queries to geodatabase. Note that we forwarded the port on the VM to the\n",
    "#local 5432 port so as to be able to talk to postgresql through the local port\n",
    "def query(query,fetch=True):\n",
    "    with Connection(host=basin.properties['ip'],\n",
    "                    user=basin.properties['username'],\n",
    "                    connect_kwargs={\"key_filename\": basin.properties['keyFile']}).forward_local(5432):\n",
    "        db = psycopg2.connect(host='localhost', port=5432, database='geosvalbard')\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(query)\n",
    "        if fetch:\n",
    "            return(cursor.fetchall()) \n",
    "\n",
    "#Setting up the connection    \n",
    "basin.setConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'plsh'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -Wall -Wpointer-arith -Wdeclaration-after-statement -Wendif-labels -Wmissing-format-attribute -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -g -g -O2 -fdebug-prefix-map=/build/postgresql-9.6-Dk87xT/postgresql-9.6-9.6.15=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -I/usr/include/mit-krb5 -fPIC -pie -fno-omit-frame-pointer -fPIC -I. -I./ -I/usr/include/postgresql/9.6/server -I/usr/include/postgresql/internal -Wdate-time -D_FORTIFY_SOURCE=2 -D_GNU_SOURCE -I/usr/include/libxml2  -I/usr/include/tcl8.6  -c -o plsh.o plsh.c\n",
      "gcc -Wall -Wpointer-arith -Wdeclaration-after-statement -Wendif-labels -Wmissing-format-attribute -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -g -g -O2 -fdebug-prefix-map=/build/postgresql-9.6-Dk87xT/postgresql-9.6-9.6.15=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -I/usr/include/mit-krb5 -fPIC -pie -fno-omit-frame-pointer -fPIC -shared -o plsh.so plsh.o -L/usr/lib/x86_64-linux-gnu  -specs=/usr/share/dpkg/no-pie-link.specs -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -L/usr/lib/mit-krb5 -L/usr/lib/x86_64-linux-gnu/mit-krb5  -Wl,--as-needed  \n",
      "cp plsh-inline.sql plsh.sql\n",
      "cp plsh.sql plsh--2.sql\n",
      "/bin/mkdir -p '/usr/lib/postgresql/9.6/lib'\n",
      "/bin/mkdir -p '/usr/share/postgresql/9.6/extension'\n",
      "/bin/mkdir -p '/usr/share/postgresql/9.6/extension'\n",
      "/usr/bin/install -c -m 755  plsh.so '/usr/lib/postgresql/9.6/lib/plsh.so'\n",
      "/usr/bin/install -c -m 644 .//plsh.control '/usr/share/postgresql/9.6/extension/'\n",
      "/usr/bin/install -c -m 644 .//plsh--unpackaged--1.sql .//plsh--1--2.sql plsh--2.sql '/usr/share/postgresql/9.6/extension/'\n",
      "GRANT\n",
      "ALTER ROLE\n",
      "ALTER ROLE\n",
      "ALTER DATABASE\n",
      "CREATE EXTENSION\n",
      "CREATE EXTENSION\n",
      "ALTER DATABASE\n",
      "ALTER DATABASE\n",
      " pg_reload_conf \n",
      "----------------\n",
      " t\n",
      "(1 row)\n",
      "\n",
      "SET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='rm script.sh' exited=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svalbardScript = '''#!/bin/bash\n",
    "\n",
    "git clone https://github.com/petere/plsh.git\n",
    "cd plsh\n",
    "make\n",
    "sudo make install\n",
    "cd ..\n",
    "\n",
    "#Allowing ssh connection to server\n",
    "sudo find /etc -name postgresql.conf -exec sudo sed -i s/.*listen_addresses.*/listen_addresses\\\\ =\\\\ \\\\'*\\\\'/g {} \\;\n",
    "sudo find /etc -name pg_hba.conf -exec sh -c \"echo host all all 151.157.0.0/16 md5>> {}\" \\;\n",
    "sudo service postgresql restart\n",
    "\n",
    "#Creating user and geosvalbard database\n",
    "sudo -u postgres createuser jose-luis\n",
    "sudo -u postgres createdb geosvalbard\n",
    "a=\\\\\\\\\\\\\\\"jose-luis\\\\\\\\\\\\\\\"\n",
    "sudo su -c \"psql -d geosvalbard -c \\\\\"grant all privileges on database geosvalbard to $a;\\\\\"\" postgres\n",
    "sudo su -c \"psql -d geosvalbard -c \\\\\"alter user $a with superuser;\\\\\"\" postgres\n",
    "sudo su -c \"psql -d geosvalbard -c \\\\\"alter user $a with password 'kakaroto';\\\\\"\" postgres\n",
    "\n",
    "#enable postgis on database\n",
    "echo \"ALTER DATABASE geosvalbard SET search_path=public, postgis, contrib, topology;\" | psql -d geosvalbard\n",
    "echo \"CREATE EXTENSION postgis CASCADE;\" | psql -d geosvalbard\n",
    "echo \"CREATE EXTENSION postgis_topology CASCADE;\" | psql -d geosvalbard\n",
    "echo \"ALTER DATABASE geosvalbard SET search_path=public, postgis, contrib, topology;\" | psql -d geosvalbard\n",
    "echo \"ALTER DATABASE geosvalbard SET postgis.gdal_enabled_drivers = ENABLE_ALL;\" | psql -d geosvalbard\n",
    "echo \"SELECT pg_reload_conf();\" | psql -d geosvalbard\n",
    "echo \"SET postgis.enable_outdb_rasters TO True;\" | psql -d geosvalbard\n",
    "sudo service postgresql restart\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "\n",
    "basin.connection.put('script.sh')\n",
    "basin.connection.run('chmod +x script.sh')\n",
    "basin.connection.run('./script.sh')\n",
    "basin.connection.run('rm script.sh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading elevation and river datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 25786P x 36896L.\n",
      "Processing input file svalbard20.tif.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25786, 36896\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "#Extracting a subset of the raster (around Adventelva)\n",
    "adventelvaY,adventelvaX = 78.20486,15.81774\n",
    "#Converting to epsg:3035\n",
    "inProj = Proj(init='epsg:4326')\n",
    "outProj = Proj(init='epsg:3035')\n",
    "x,y = transform(inProj,outProj,adventelvaX,adventelvaY)\n",
    "offset=120000\n",
    "box={'ulx': x - offset, 'uly': y + offset , 'lrx': x + offset , 'lry': y - offset }\n",
    "\n",
    "svalbardScript='''#!/bin/bash\n",
    "#Getting 20m DEM\n",
    "wget -q http://publicdatasets.data.npolar.no/kartdata/NP_S0_DTM20.zip \n",
    "unzip -q *.zip\n",
    "rm *.zip\n",
    "find ./ -name *.tif -exec mv {{}} svalbard20.tif \\\\;\n",
    "\n",
    "gdalwarp -s_srs EPSG:32633 -t_srs EPSG:3035 -r cubicspline -overwrite -srcnodata 0.0 -dstnodata -9999 svalbard20.tif svalbard20_3035.tif\n",
    "#gdalwarp -s_srs EPSG:32633 -t_srs EPSG:4326 -r cubicspline -overwrite -srcnodata 0.0 -dstnodata -9999 svalbard20.tif svalbard20_4326.tif\n",
    "\n",
    "rm -f svalbard20_3035_subset.tif\n",
    "gdal_translate -projwin {ulx} {uly} {lrx} {lry} svalbard20_3035.tif svalbard20_3035_subset.tif\n",
    "#gdalwarp -s_srs EPSG:3035 -t_srs EPSG:4326 -r cubicspline -overwrite -srcnodata -3.4028234663852886e+38 -dstnodata -9999 svalbard20_3035_subset.tif svalbard20_4326_subset.tif\n",
    "#gdal_translate -of \"Envi\" svalbard20_4326_subset.tif ./LSDTopoTools/Git_projects/LSDTopoTools_ChannelExtraction/driver_functions_ChannelExtraction/svalbard.bil\n",
    "#gdal_translate -of \"AAIGrid\" svalbard20_4326_subset.tif ./LSDTopoTools/Git_projects/LSDTopoTools_ChannelExtraction/driver_functions_ChannelExtraction/svalbard.ascii\n",
    "\n",
    "#Getting rivers\n",
    "#wget https://nedlasting.geonorge.no/api/download/order/a867cb2b-c1bb-43dc-9939-6f7365754d29/224b3a20-4572-4f79-ad77-440509dabae5-O svalbard.zip\n",
    "#unzip svalbard.zip #&& mv NP_S100_SOS svalbard\n",
    "\n",
    "#Getting sosicon\n",
    "#wget https://github.com/espena/sosicon/blob/master/bin/cmd/linux64/sosicon?raw=true -O sosicon && chmod +x sosicon && mv sosicon ./svalbard/\n",
    "'''.format(**box)\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "    \n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Taudem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 6.3.0\n",
      "-- The CXX compiler identification is GNU 6.3.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found MPI_C: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so  \n",
      "-- Found MPI_CXX: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so;/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so  \n",
      "-- Found GDAL: /usr/lib/libgdal.so  \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/jose-luis/taudem/src/build\n",
      "Scanning dependencies of target streamnet\n",
      "[  1%] Building CXX object CMakeFiles/streamnet.dir/streamnetmn.cpp.o\n",
      "[  1%] Building CXX object CMakeFiles/streamnet.dir/streamnet.cpp.o\n",
      "[  2%] Building CXX object CMakeFiles/streamnet.dir/commonLib.cpp.o\n",
      "[  3%] Building CXX object CMakeFiles/streamnet.dir/tiffIO.cpp.o\n",
      "[  3%] Building CXX object CMakeFiles/streamnet.dir/ReadOutlets.cpp.o\n",
      "[  4%] Linking CXX executable streamnet\n",
      "[  4%] Built target streamnet\n",
      "Scanning dependencies of target slopeavedown\n",
      "[  5%] Building CXX object CMakeFiles/slopeavedown.dir/SlopeAveDown.cpp.o\n",
      "[  6%] Building CXX object CMakeFiles/slopeavedown.dir/SlopeAveDownmn.cpp.o\n",
      "[  7%] Building CXX object CMakeFiles/slopeavedown.dir/commonLib.cpp.o\n",
      "[  7%] Building CXX object CMakeFiles/slopeavedown.dir/tiffIO.cpp.o\n",
      "[  8%] Linking CXX executable slopeavedown\n",
      "[  8%] Built target slopeavedown\n",
      "Scanning dependencies of target dinfdistdown\n",
      "[  9%] Building CXX object CMakeFiles/dinfdistdown.dir/DinfDistDown.cpp.o\n",
      "[  9%] Building CXX object CMakeFiles/dinfdistdown.dir/DinfDistDownmn.cpp.o\n",
      "[ 10%] Building CXX object CMakeFiles/dinfdistdown.dir/commonLib.cpp.o\n",
      "[ 11%] Building CXX object CMakeFiles/dinfdistdown.dir/tiffIO.cpp.o\n",
      "[ 11%] Linking CXX executable dinfdistdown\n",
      "[ 11%] Built target dinfdistdown\n",
      "Scanning dependencies of target moveoutletstostrm\n",
      "[ 11%] Building CXX object CMakeFiles/moveoutletstostrm.dir/MoveOutletsToStrm.cpp.o\n",
      "[ 12%] Building CXX object CMakeFiles/moveoutletstostrm.dir/MoveOutletsToStrmmn.cpp.o\n",
      "[ 13%] Building CXX object CMakeFiles/moveoutletstostrm.dir/commonLib.cpp.o\n",
      "[ 13%] Building CXX object CMakeFiles/moveoutletstostrm.dir/tiffIO.cpp.o\n",
      "[ 14%] Building CXX object CMakeFiles/moveoutletstostrm.dir/ReadOutlets.cpp.o\n",
      "[ 15%] Linking CXX executable moveoutletstostrm\n",
      "[ 15%] Built target moveoutletstostrm\n",
      "Scanning dependencies of target dinfdecayaccum\n",
      "[ 15%] Building CXX object CMakeFiles/dinfdecayaccum.dir/dinfdecayaccum.cpp.o\n",
      "[ 16%] Building CXX object CMakeFiles/dinfdecayaccum.dir/DinfDecayAccummn.cpp.o\n",
      "[ 17%] Building CXX object CMakeFiles/dinfdecayaccum.dir/commonLib.cpp.o\n",
      "[ 18%] Building CXX object CMakeFiles/dinfdecayaccum.dir/tiffIO.cpp.o\n",
      "[ 18%] Building CXX object CMakeFiles/dinfdecayaccum.dir/ReadOutlets.cpp.o\n",
      "[ 19%] Linking CXX executable dinfdecayaccum\n",
      "[ 19%] Built target dinfdecayaccum\n",
      "Scanning dependencies of target dinfdistup\n",
      "[ 20%] Building CXX object CMakeFiles/dinfdistup.dir/DinfDistUp.cpp.o\n",
      "[ 21%] Building CXX object CMakeFiles/dinfdistup.dir/DinfDistUpmn.cpp.o\n",
      "[ 21%] Building CXX object CMakeFiles/dinfdistup.dir/commonLib.cpp.o\n",
      "[ 22%] Building CXX object CMakeFiles/dinfdistup.dir/tiffIO.cpp.o\n",
      "[ 23%] Linking CXX executable dinfdistup\n",
      "[ 23%] Built target dinfdistup\n",
      "Scanning dependencies of target gagewatershed\n",
      "[ 24%] Building CXX object CMakeFiles/gagewatershed.dir/gagewatershedmn.cpp.o\n",
      "[ 24%] Building CXX object CMakeFiles/gagewatershed.dir/gagewatershed.cpp.o\n",
      "[ 25%] Building CXX object CMakeFiles/gagewatershed.dir/commonLib.cpp.o\n",
      "[ 26%] Building CXX object CMakeFiles/gagewatershed.dir/tiffIO.cpp.o\n",
      "[ 26%] Building CXX object CMakeFiles/gagewatershed.dir/ReadOutlets.cpp.o\n",
      "[ 27%] Linking CXX executable gagewatershed\n",
      "[ 27%] Built target gagewatershed\n",
      "Scanning dependencies of target aread8\n",
      "[ 27%] Building CXX object CMakeFiles/aread8.dir/aread8mn.cpp.o\n",
      "[ 28%] Building CXX object CMakeFiles/aread8.dir/aread8.cpp.o\n",
      "[ 29%] Building CXX object CMakeFiles/aread8.dir/commonLib.cpp.o\n",
      "[ 29%] Building CXX object CMakeFiles/aread8.dir/tiffIO.cpp.o\n",
      "[ 30%] Building CXX object CMakeFiles/aread8.dir/ReadOutlets.cpp.o\n",
      "[ 31%] Linking CXX executable aread8\n",
      "[ 31%] Built target aread8\n",
      "Scanning dependencies of target lengtharea\n",
      "[ 32%] Building CXX object CMakeFiles/lengtharea.dir/LengthArea.cpp.o\n",
      "[ 32%] Building CXX object CMakeFiles/lengtharea.dir/LengthAreamn.cpp.o\n",
      "[ 33%] Building CXX object CMakeFiles/lengtharea.dir/commonLib.cpp.o\n",
      "[ 34%] Building CXX object CMakeFiles/lengtharea.dir/tiffIO.cpp.o\n",
      "[ 35%] Linking CXX executable lengtharea\n",
      "[ 35%] Built target lengtharea\n",
      "Scanning dependencies of target dinfconclimaccum\n",
      "[ 35%] Building CXX object CMakeFiles/dinfconclimaccum.dir/DinfConcLimAccum.cpp.o\n",
      "[ 36%] Building CXX object CMakeFiles/dinfconclimaccum.dir/DinfConcLimAccummn.cpp.o\n",
      "[ 37%] Building CXX object CMakeFiles/dinfconclimaccum.dir/commonLib.cpp.o\n",
      "[ 37%] Building CXX object CMakeFiles/dinfconclimaccum.dir/tiffIO.cpp.o\n",
      "[ 38%] Building CXX object CMakeFiles/dinfconclimaccum.dir/ReadOutlets.cpp.o\n",
      "[ 39%] Linking CXX executable dinfconclimaccum\n",
      "[ 39%] Built target dinfconclimaccum\n",
      "Scanning dependencies of target gridnet\n",
      "[ 40%] Building CXX object CMakeFiles/gridnet.dir/gridnetmn.cpp.o\n",
      "[ 40%] Building CXX object CMakeFiles/gridnet.dir/gridnet.cpp.o\n",
      "[ 41%] Building CXX object CMakeFiles/gridnet.dir/commonLib.cpp.o\n",
      "[ 42%] Building CXX object CMakeFiles/gridnet.dir/tiffIO.cpp.o\n",
      "[ 42%] Building CXX object CMakeFiles/gridnet.dir/ReadOutlets.cpp.o\n",
      "[ 43%] Linking CXX executable gridnet\n",
      "[ 43%] Built target gridnet\n",
      "Scanning dependencies of target d8hdisttostrm\n",
      "[ 43%] Building CXX object CMakeFiles/d8hdisttostrm.dir/D8HDistToStrm.cpp.o\n",
      "[ 44%] Building CXX object CMakeFiles/d8hdisttostrm.dir/D8HDistToStrmmn.cpp.o\n",
      "[ 45%] Building CXX object CMakeFiles/d8hdisttostrm.dir/commonLib.cpp.o\n",
      "[ 46%] Building CXX object CMakeFiles/d8hdisttostrm.dir/tiffIO.cpp.o\n",
      "[ 46%] Linking CXX executable d8hdisttostrm\n",
      "[ 46%] Built target d8hdisttostrm\n",
      "Scanning dependencies of target d8flowdir\n",
      "[ 46%] Building CXX object CMakeFiles/d8flowdir.dir/D8FlowDirmn.cpp.o\n",
      "[ 47%] Building CXX object CMakeFiles/d8flowdir.dir/d8.cpp.o\n",
      "[ 48%] Building CXX object CMakeFiles/d8flowdir.dir/Node.cpp.o\n",
      "[ 49%] Building CXX object CMakeFiles/d8flowdir.dir/commonLib.cpp.o\n",
      "[ 49%] Building CXX object CMakeFiles/d8flowdir.dir/tiffIO.cpp.o\n",
      "[ 50%] Building CXX object CMakeFiles/d8flowdir.dir/ReadOutlets.cpp.o\n",
      "[ 51%] Linking CXX executable d8flowdir\n",
      "[ 51%] Built target d8flowdir\n",
      "Scanning dependencies of target dinfupdependence\n",
      "[ 52%] Building CXX object CMakeFiles/dinfupdependence.dir/DinfUpDependence.cpp.o\n",
      "[ 53%] Building CXX object CMakeFiles/dinfupdependence.dir/DinfUpDependencemn.cpp.o\n",
      "[ 53%] Building CXX object CMakeFiles/dinfupdependence.dir/commonLib.cpp.o\n",
      "[ 54%] Building CXX object CMakeFiles/dinfupdependence.dir/tiffIO.cpp.o\n",
      "[ 55%] Linking CXX executable dinfupdependence\n",
      "[ 55%] Built target dinfupdependence\n",
      "Scanning dependencies of target areadinf\n",
      "[ 55%] Building CXX object CMakeFiles/areadinf.dir/areadinfmn.cpp.o\n",
      "[ 56%] Building CXX object CMakeFiles/areadinf.dir/areadinf.cpp.o\n",
      "[ 57%] Building CXX object CMakeFiles/areadinf.dir/commonLib.cpp.o\n",
      "[ 57%] Building CXX object CMakeFiles/areadinf.dir/tiffIO.cpp.o\n",
      "[ 58%] Building CXX object CMakeFiles/areadinf.dir/ReadOutlets.cpp.o\n",
      "[ 59%] Linking CXX executable areadinf\n",
      "[ 59%] Built target areadinf\n",
      "Scanning dependencies of target pitremove\n",
      "[ 60%] Building CXX object CMakeFiles/pitremove.dir/flood.cpp.o\n",
      "[ 61%] Building CXX object CMakeFiles/pitremove.dir/PitRemovemn.cpp.o\n",
      "[ 61%] Building CXX object CMakeFiles/pitremove.dir/commonLib.cpp.o\n",
      "[ 62%] Building CXX object CMakeFiles/pitremove.dir/tiffIO.cpp.o\n",
      "[ 63%] Linking CXX executable pitremove\n",
      "[ 63%] Built target pitremove\n",
      "Scanning dependencies of target peukerdouglas\n",
      "[ 63%] Building CXX object CMakeFiles/peukerdouglas.dir/PeukerDouglas.cpp.o\n",
      "[ 64%] Building CXX object CMakeFiles/peukerdouglas.dir/PeukerDouglasmn.cpp.o\n",
      "[ 65%] Building CXX object CMakeFiles/peukerdouglas.dir/commonLib.cpp.o\n",
      "[ 65%] Building CXX object CMakeFiles/peukerdouglas.dir/tiffIO.cpp.o\n",
      "[ 66%] Linking CXX executable peukerdouglas\n",
      "[ 66%] Built target peukerdouglas\n",
      "Scanning dependencies of target threshold\n",
      "[ 67%] Building CXX object CMakeFiles/threshold.dir/Threshold.cpp.o\n",
      "[ 67%] Building CXX object CMakeFiles/threshold.dir/Thresholdmn.cpp.o\n",
      "[ 68%] Building CXX object CMakeFiles/threshold.dir/commonLib.cpp.o\n",
      "[ 69%] Building CXX object CMakeFiles/threshold.dir/tiffIO.cpp.o\n",
      "[ 70%] Linking CXX executable threshold\n",
      "[ 70%] Built target threshold\n",
      "Scanning dependencies of target dinftranslimaccum\n",
      "[ 71%] Building CXX object CMakeFiles/dinftranslimaccum.dir/DinfTransLimAccum.cpp.o\n",
      "[ 71%] Building CXX object CMakeFiles/dinftranslimaccum.dir/DinfTransLimAccummn.cpp.o\n",
      "[ 72%] Building CXX object CMakeFiles/dinftranslimaccum.dir/commonLib.cpp.o\n",
      "[ 73%] Building CXX object CMakeFiles/dinftranslimaccum.dir/tiffIO.cpp.o\n",
      "[ 74%] Building CXX object CMakeFiles/dinftranslimaccum.dir/ReadOutlets.cpp.o\n",
      "[ 74%] Linking CXX executable dinftranslimaccum\n",
      "[ 74%] Built target dinftranslimaccum\n",
      "Scanning dependencies of target dinfflowdir\n",
      "[ 75%] Building CXX object CMakeFiles/dinfflowdir.dir/DinfFlowDirmn.cpp.o\n",
      "[ 75%] Building CXX object CMakeFiles/dinfflowdir.dir/dinf.cpp.o\n",
      "[ 76%] Building CXX object CMakeFiles/dinfflowdir.dir/Node.cpp.o\n",
      "[ 77%] Building CXX object CMakeFiles/dinfflowdir.dir/commonLib.cpp.o\n",
      "[ 77%] Building CXX object CMakeFiles/dinfflowdir.dir/tiffIO.cpp.o\n",
      "[ 78%] Building CXX object CMakeFiles/dinfflowdir.dir/ReadOutlets.cpp.o\n",
      "[ 79%] Linking CXX executable dinfflowdir\n",
      "[ 79%] Built target dinfflowdir\n",
      "Scanning dependencies of target d8flowpathextremeup\n",
      "[ 79%] Building CXX object CMakeFiles/d8flowpathextremeup.dir/D8flowpathextremeup.cpp.o\n",
      "[ 80%] Building CXX object CMakeFiles/d8flowpathextremeup.dir/D8FlowPathExtremeUpmn.cpp.o\n",
      "[ 81%] Building CXX object CMakeFiles/d8flowpathextremeup.dir/commonLib.cpp.o\n",
      "[ 81%] Building CXX object CMakeFiles/d8flowpathextremeup.dir/tiffIO.cpp.o\n",
      "[ 82%] Building CXX object CMakeFiles/d8flowpathextremeup.dir/ReadOutlets.cpp.o\n",
      "[ 83%] Linking CXX executable d8flowpathextremeup\n",
      "[ 83%] Built target d8flowpathextremeup\n",
      "Scanning dependencies of target dinfrevaccum\n",
      "[ 83%] Building CXX object CMakeFiles/dinfrevaccum.dir/DinfRevAccum.cpp.o\n",
      "[ 84%] Building CXX object CMakeFiles/dinfrevaccum.dir/DinfRevAccummn.cpp.o\n",
      "[ 85%] Building CXX object CMakeFiles/dinfrevaccum.dir/commonLib.cpp.o\n",
      "[ 85%] Building CXX object CMakeFiles/dinfrevaccum.dir/tiffIO.cpp.o\n",
      "[ 86%] Linking CXX executable dinfrevaccum\n",
      "[ 86%] Built target dinfrevaccum\n",
      "Scanning dependencies of target dropanalysis\n",
      "[ 86%] Building CXX object CMakeFiles/dropanalysis.dir/DropAnalysis.cpp.o\n",
      "[ 87%] Building CXX object CMakeFiles/dropanalysis.dir/DropAnalysismn.cpp.o\n",
      "[ 88%] Building CXX object CMakeFiles/dropanalysis.dir/commonLib.cpp.o\n",
      "[ 88%] Building CXX object CMakeFiles/dropanalysis.dir/tiffIO.cpp.o\n",
      "[ 89%] Building CXX object CMakeFiles/dropanalysis.dir/ReadOutlets.cpp.o\n",
      "[ 90%] Linking CXX executable dropanalysis\n",
      "[ 90%] Built target dropanalysis\n",
      "Scanning dependencies of target dinfavalanche\n",
      "[ 91%] Building CXX object CMakeFiles/dinfavalanche.dir/DinfAvalanche.cpp.o\n",
      "[ 92%] Building CXX object CMakeFiles/dinfavalanche.dir/DinfAvalanchemn.cpp.o\n",
      "[ 92%] Building CXX object CMakeFiles/dinfavalanche.dir/commonLib.cpp.o\n",
      "[ 93%] Building CXX object CMakeFiles/dinfavalanche.dir/tiffIO.cpp.o\n",
      "[ 94%] Linking CXX executable dinfavalanche\n",
      "[ 94%] Built target dinfavalanche\n",
      "Scanning dependencies of target slopearea\n",
      "[ 94%] Building CXX object CMakeFiles/slopearea.dir/SlopeArea.cpp.o\n",
      "[ 95%] Building CXX object CMakeFiles/slopearea.dir/SlopeAreamn.cpp.o\n",
      "[ 96%] Building CXX object CMakeFiles/slopearea.dir/commonLib.cpp.o\n",
      "[ 96%] Building CXX object CMakeFiles/slopearea.dir/tiffIO.cpp.o\n",
      "[ 97%] Linking CXX executable slopearea\n",
      "[ 97%] Built target slopearea\n",
      "Scanning dependencies of target slopearearatio\n",
      "[ 98%] Building CXX object CMakeFiles/slopearearatio.dir/SlopeAreaRatio.cpp.o\n",
      "[ 98%] Building CXX object CMakeFiles/slopearearatio.dir/SlopeAreaRatiomn.cpp.o\n",
      "[ 99%] Building CXX object CMakeFiles/slopearearatio.dir/commonLib.cpp.o\n",
      "[100%] Building CXX object CMakeFiles/slopearearatio.dir/tiffIO.cpp.o\n",
      "[100%] Linking CXX executable slopearearatio\n",
      "[100%] Built target slopearearatio\n",
      "[  4%] Built target streamnet\n",
      "[  8%] Built target slopeavedown\n",
      "[ 11%] Built target dinfdistdown\n",
      "[ 15%] Built target moveoutletstostrm\n",
      "[ 19%] Built target dinfdecayaccum\n",
      "[ 23%] Built target dinfdistup\n",
      "[ 27%] Built target gagewatershed\n",
      "[ 31%] Built target aread8\n",
      "[ 35%] Built target lengtharea\n",
      "[ 39%] Built target dinfconclimaccum\n",
      "[ 43%] Built target gridnet\n",
      "[ 46%] Built target d8hdisttostrm\n",
      "[ 51%] Built target d8flowdir\n",
      "[ 55%] Built target dinfupdependence\n",
      "[ 59%] Built target areadinf\n",
      "[ 63%] Built target pitremove\n",
      "[ 66%] Built target peukerdouglas\n",
      "[ 70%] Built target threshold\n",
      "[ 74%] Built target dinftranslimaccum\n",
      "[ 79%] Built target dinfflowdir\n",
      "[ 83%] Built target d8flowpathextremeup\n",
      "[ 86%] Built target dinfrevaccum\n",
      "[ 90%] Built target dropanalysis\n",
      "[ 94%] Built target dinfavalanche\n",
      "[ 97%] Built target slopearea\n",
      "[100%] Built target slopearearatio\n",
      "Install the project...\n",
      "-- Install configuration: \"\"\n",
      "-- Installing: /usr/local/bin/aread8\n",
      "-- Set runtime path of \"/usr/local/bin/aread8\" to \"\"\n",
      "-- Installing: /usr/local/bin/areadinf\n",
      "-- Set runtime path of \"/usr/local/bin/areadinf\" to \"\"\n",
      "-- Installing: /usr/local/bin/d8flowdir\n",
      "-- Set runtime path of \"/usr/local/bin/d8flowdir\" to \"\"\n",
      "-- Installing: /usr/local/bin/d8flowpathextremeup\n",
      "-- Set runtime path of \"/usr/local/bin/d8flowpathextremeup\" to \"\"\n",
      "-- Installing: /usr/local/bin/d8hdisttostrm\n",
      "-- Set runtime path of \"/usr/local/bin/d8hdisttostrm\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfavalanche\n",
      "-- Set runtime path of \"/usr/local/bin/dinfavalanche\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfconclimaccum\n",
      "-- Set runtime path of \"/usr/local/bin/dinfconclimaccum\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfdecayaccum\n",
      "-- Set runtime path of \"/usr/local/bin/dinfdecayaccum\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfdistdown\n",
      "-- Set runtime path of \"/usr/local/bin/dinfdistdown\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfdistup\n",
      "-- Set runtime path of \"/usr/local/bin/dinfdistup\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfflowdir\n",
      "-- Set runtime path of \"/usr/local/bin/dinfflowdir\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfrevaccum\n",
      "-- Set runtime path of \"/usr/local/bin/dinfrevaccum\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinftranslimaccum\n",
      "-- Set runtime path of \"/usr/local/bin/dinftranslimaccum\" to \"\"\n",
      "-- Installing: /usr/local/bin/dinfupdependence\n",
      "-- Set runtime path of \"/usr/local/bin/dinfupdependence\" to \"\"\n",
      "-- Installing: /usr/local/bin/dropanalysis\n",
      "-- Set runtime path of \"/usr/local/bin/dropanalysis\" to \"\"\n",
      "-- Installing: /usr/local/bin/gridnet\n",
      "-- Set runtime path of \"/usr/local/bin/gridnet\" to \"\"\n",
      "-- Installing: /usr/local/bin/lengtharea\n",
      "-- Set runtime path of \"/usr/local/bin/lengtharea\" to \"\"\n",
      "-- Installing: /usr/local/bin/moveoutletstostrm\n",
      "-- Set runtime path of \"/usr/local/bin/moveoutletstostrm\" to \"\"\n",
      "-- Installing: /usr/local/bin/peukerdouglas\n",
      "-- Set runtime path of \"/usr/local/bin/peukerdouglas\" to \"\"\n",
      "-- Installing: /usr/local/bin/pitremove\n",
      "-- Set runtime path of \"/usr/local/bin/pitremove\" to \"\"\n",
      "-- Installing: /usr/local/bin/slopearea\n",
      "-- Set runtime path of \"/usr/local/bin/slopearea\" to \"\"\n",
      "-- Installing: /usr/local/bin/slopearearatio\n",
      "-- Set runtime path of \"/usr/local/bin/slopearearatio\" to \"\"\n",
      "-- Installing: /usr/local/bin/slopeavedown\n",
      "-- Set runtime path of \"/usr/local/bin/slopeavedown\" to \"\"\n",
      "-- Installing: /usr/local/bin/streamnet\n",
      "-- Set runtime path of \"/usr/local/bin/streamnet\" to \"\"\n",
      "-- Installing: /usr/local/bin/threshold\n",
      "-- Set runtime path of \"/usr/local/bin/threshold\" to \"\"\n",
      "-- Installing: /usr/local/bin/gagewatershed\n",
      "-- Set runtime path of \"/usr/local/bin/gagewatershed\" to \"\"\n"
     ]
    }
   ],
   "source": [
    "svalbardScript = '''#!/bin/bash\n",
    "mkdir -p taudem\n",
    "git clone https://github.com/dtarb/TauDEM.git --branch master --single-branch ./taudem\n",
    "cd taudem/src\n",
    "mkdir build && cd build\n",
    "cmake ..\n",
    "make\n",
    "sudo make install\n",
    "cd ~\n",
    "\n",
    "#Installing lsdtopotools\n",
    "#git clone https://github.com/LSDtopotools/LSDTopoTools2.git\n",
    "#cd LSDTopoTools2\n",
    "#sh lsdtt2_setup.sh\n",
    "\n",
    "#wget https://raw.githubusercontent.com/LSDtopotools/LSDAutomation/master/LSDTopoToolsSetup.py\n",
    "#python LSDTopoToolsSetup.py -id 1 -CE True\n",
    "\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "    \n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh',hide='stderr')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PitRemove version 5.3.8\n",
      "Input file svalbard20_3035_subset.tif has projected coordinate system.\n",
      "Processes: 16\n",
      "Header read time: 0.135610\n",
      "Data read time: 0.046603\n",
      "Compute time: 12.114633\n",
      "Write time: 8.001466\n",
      "Total time: 20.298312\n",
      "D8FlowDir version 5.3.8\n",
      "Input file fel.tif has projected coordinate system.\n",
      "Processors: 16\n",
      "Header read time: 0.136489\n",
      "Data read time: 0.395408\n",
      "Compute Slope time: 4.714039\n",
      "Write Slope time: 9.571317\n",
      "Resolve Flat time: 93.143994\n",
      "Write Flat time: 3.151290\n",
      "Total time: 111.112537\n",
      "AreaD8 version 5.3.8\n",
      "Input file flow_dir.tif has projected coordinate system.\n",
      "Number of Processes: 16\n",
      "Read time: 0.211355\n",
      "Compute time: 9.848134\n",
      "Write time: 2.959143\n",
      "Total time: 13.018632\n",
      "Threshold version 5.3.8\n",
      "Input file flow_acc.tif has projected coordinate system.\n",
      "Compute time: 0.511579\n",
      "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
      "Input file size is 12040, 12040\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
      "PitRemove version 5.3.8\n",
      "Input file el.tif has projected coordinate system.\n",
      "Processes: 16\n",
      "Header read time: 0.137686\n",
      "Data read time: 0.045641\n",
      "Compute time: 17.552015\n",
      "Write time: 8.011006\n",
      "Total time: 25.746348\n",
      "D8FlowDir version 5.3.8\n",
      "Input file fel.tif has projected coordinate system.\n",
      "Processors: 16\n",
      "Header read time: 0.137538\n",
      "Data read time: 0.391822\n",
      "Compute Slope time: 4.699896\n",
      "Write Slope time: 9.639219\n",
      "Resolve Flat time: 158.711208\n",
      "Write Flat time: 3.208458\n",
      "Total time: 176.788141\n",
      "AreaD8 version 5.3.8\n",
      "Input file flow_dir.tif has projected coordinate system.\n",
      "Number of Processes: 16\n",
      "Read time: 0.224523\n",
      "Compute time: 9.944115\n",
      "Write time: 2.925901\n",
      "Total time: 13.094539\n",
      "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
      "Input file size is 12040, 12040\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "____________________________\n",
      "\n",
      "   #####   ##   #####    ##\n",
      "  ###     ###  ##       ###\n",
      "   ###   # ## ##  #### # ##\n",
      "    ### ##### ##    # #####\n",
      " ##### #   ##  ##### #   ##\n",
      "____________________________\n",
      "\n",
      "SAGA Version: 2.3.1\n",
      "\n",
      "____________________________\n",
      "library path: /usr/lib/x86_64-linux-gnu/saga/\n",
      "library name: libimagery_segmentation\n",
      "library     : Segmentation\n",
      "tool        : Grid Skeletonization\n",
      "author      : O.Conrad (c) 2002\n",
      "processors  : 16 [16]\n",
      "____________________________\n",
      "\n",
      "loading: bit_river\n",
      "\n",
      "100%\n",
      "\n",
      "Parameters\n",
      "\n",
      "\n",
      "Grid system: 19.933842; 12040x 12040y; 4337222.530837x 5991151.725689y\n",
      "Grid: bit_river\n",
      "Skeleton: Skeleton\n",
      "Skeleton: Skeleton\n",
      "Method: Standard\n",
      "Initialisation: Greater than\n",
      "Threshold (Init.): 0.000000\n",
      "Convergence: 0\n",
      "\n",
      "/   \n",
      "100%Grid Skeletonization: 17051 segments identified\n",
      "\n",
      "Save shapes: ./river.shp...\n",
      "\n",
      "100%okay\n"
     ]
    }
   ],
   "source": [
    "svalbardScript = '''#!/bin/bash\n",
    "n=`nproc`\n",
    "rm fel.tif\n",
    "rm flow_dir.tif\n",
    "rm flow_acc.tif\n",
    "rm streams.tif\n",
    "rm river*\n",
    "rm fa.tif\n",
    "\n",
    "mpiexec -n $n pitremove -z svalbard20_3035_subset.tif -fel fel.tif\n",
    "mpiexec -n $n d8flowdir -fel fel.tif -p flow_dir.tif\n",
    "mpiexec -n $n aread8 -p flow_dir.tif -nc -ad8 flow_acc.tif\n",
    "mpiexec -n $n threshold -ssa flow_acc.tif -thresh 800 -src streams.tif\n",
    "\n",
    "cp flow_acc.tif fa.tif\n",
    "gdal_edit.py fa.tif -unsetnodata\n",
    "gdal_calc.py -A fa.tif --overwrite --outfile=river.tif --calc=\"A>2500 * logical_not(A==-9999)\" --type Byte\n",
    "gdal_translate -co \"NBITS=1\" river.tif bit_river.tif\n",
    "\n",
    "rm fel.tif\n",
    "rm flow_dir.tif\n",
    "rm flow_acc.tif\n",
    "rm streams.tif\n",
    "rm river.tif\n",
    "rm fa.tif\n",
    "rm el.tif\n",
    "\n",
    "gdal_calc.py -A svalbard20_3035_subset.tif -B bit_river.tif --outfile=el.tif --calc=\"A-B*10\" \n",
    "mpiexec -n $n pitremove -z el.tif -fel fel.tif\n",
    "mpiexec -n $n d8flowdir -fel fel.tif -p flow_dir.tif\n",
    "mpiexec -n $n aread8 -p flow_dir.tif -nc -ad8 flow_acc.tif\n",
    "\n",
    "rm bit_river.tif\n",
    "\n",
    "cp flow_acc.tif fa.tif\n",
    "gdal_edit.py fa.tif -unsetnodata\n",
    "gdal_calc.py -A fa.tif --overwrite --outfile=river.tif --calc=\"A>2500 * logical_not(A==-9999)\" --type Byte\n",
    "gdal_translate -co \"NBITS=1\" river.tif bit_river.tif\n",
    "\n",
    "saga_cmd imagery_segmentation \"Grid Skeletonization\" -INPUT bit_river.tif -METHOD 0 -INIT_METHOD 1 -INIT_THRESHOLD 0 -CONVERGENCE 0 -VECTOR \"./river.shp\"\n",
    "'''\n",
    "#Cloning and installing taudem\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh', hide='stderr')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading flow_direction and elevation rasters to database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up procedures on geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP SCHEMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE:  schema \"procedures\" does not exist, skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTENSION\n",
      "DROP TYPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE:  type \"station_info\" does not exist, skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TYPE\n"
     ]
    }
   ],
   "source": [
    "svalbardScript = '''#!/bin/bash\n",
    "read -r -d '' sql <<-EOM\n",
    "DROP SCHEMA IF EXISTS procedures CASCADE;\n",
    "CREATE EXTENSION IF NOT EXISTS plsh;\n",
    "DROP TYPE IF EXISTS station_info CASCADE;  \n",
    "CREATE TYPE station_info AS (\n",
    "station_name varchar(80),\n",
    "station_id INTEGER,\n",
    "longitude DOUBLE PRECISION,\n",
    "latitude DOUBLE PRECISION,\n",
    "buffer DOUBLE PRECISION,    \n",
    "epsg INTEGER,\n",
    "mask TEXT\n",
    ");\n",
    "EOM\n",
    "\n",
    "echo $sql | psql -d geosvalbard\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET\n",
      "SET\n",
      "SET\n",
      "SET\n",
      "SET\n",
      " set_config \n",
      "------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      "SET\n",
      "SET\n",
      "SET\n",
      "SET\n",
      "CREATE SCHEMA\n",
      "ALTER SCHEMA\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n",
      "CREATE FUNCTION\n",
      "ALTER FUNCTION\n"
     ]
    }
   ],
   "source": [
    "#The procedures.sql file is downloaded from geonorway: \n",
    "#pg_dump --schema=schema_name db_name > backupfile.sql\n",
    "# and uploaded to this new database\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('/home/jose-luis/Downloads/procedures_oct.sql')\n",
    "    c.run('psql -d geosvalbard < procedures_oct.sql')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE SCHEMA\n",
      "                      addgeometrycolumn                      \n",
      "-------------------------------------------------------------\n",
      " svalbard.rivers.geom SRID:3035 TYPE:MULTILINESTRING DIMS:2 \n",
      "(1 row)\n",
      "\n",
      " setextenttable \n",
      "----------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      " setextenttable \n",
      "----------------\n",
      " \n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svalbardScript = '''#!/bin/bash\n",
    "echo \"DROP SCHEMA svalbard CASCADE;\" | psql -d geosvalbard\n",
    "echo \"CREATE SCHEMA svalbard;\" | psql -d geosvalbard\n",
    "#Putting rivers in database\n",
    "shp2pgsql -I -d -s 3035 river.shp svalbard.rivers | psql -q -d geosvalbard\n",
    "#Putting rasters in database\n",
    "raster2pgsql -I -M -F -b 1 -r -s 3035 -d -t auto flow_dir.tif  svalbard.flow_dir | psql -q -d geosvalbard\n",
    "raster2pgsql -I -M -F -b 1 -r -s 3035 -d -t auto svalbard20_3035_subset.tif  svalbard.el | psql -q -d geosvalbard\n",
    "\n",
    "echo \"SELECT procedures.setExtentTable('svalbard','flow_dir');\" | psql -d geosvalbard\n",
    "echo \"SELECT procedures.setExtentTable('svalbard','el');\" | psql -d geosvalbard\n",
    "\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh',hide='stderr')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating yaml file with stations list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ARRAY[row('Adventelva',1,15.82857,78.20388,75000,4326,'')::station_info,row('Endalselva',2,15.816164,78.200545,75000,4326,'')::station_info,row('Todalselva',3,15.86485,78.17167,75000,4326,'')::station_info,row('Bolterelva',4,15.98027,78.16333,75000,4326,'')::station_info,row('Foxelva',5,16.20452,78.15919,75000,4326,'')::station_info,row('AdventelvaSea',6,15.7447349,78.2272992,75000,4326,'')::station_info,row('DeGeerelva',7,16.31238,78.33822,75000,4326,'')::station_info,row('Sassenelva',8,16.86129,78.33203,75000,4326,'')::station_info,row('SassenelvaSea',9,16.85598,78.33648,75000,4326,'')::station_info,row('Gipsdalselva',10,16.57706,78.44082,75000,4326,'')::station_info,row('Ebbaelva',11,16.599771,78.70824,75000,4326,'')::station_info]\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1 2 3 4 5 6 7 8 9 10 11'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "coords=[\n",
    "{'name': 'Adventelva', 'latitude': 78.20388, 'longitude': 15.82857, 'id':1},\n",
    "{'name': 'Endalselva', 'latitude': 78.200545, 'longitude': 15.816164, 'id':2},\n",
    "{'name': 'Todalselva', 'latitude': 78.17167, 'longitude': 15.86485, 'id':3},    \n",
    "{'name': 'Bolterelva', 'latitude': 78.16333, 'longitude': 15.98027, 'id':4},\n",
    "{'name': 'Foxelva',    'latitude': 78.15919, 'longitude': 16.20452, 'id':5},\n",
    "{'name': 'AdventelvaSea', 'latitude': 78.2272992, 'longitude': 15.7447349, 'id': 6}, \n",
    "{'name': 'DeGeerelva',    'latitude': 78.33822, 'longitude': 16.31238, 'id':7},\n",
    "{'name': 'Sassenelva',    'latitude': 78.33203, 'longitude': 16.86129, 'id':8},\n",
    "{'name': 'SassenelvaSea', 'latitude': 78.33648, 'longitude': 16.85598, 'id':9},\n",
    "{'name': 'Gipsdalselva',  'latitude': 78.44082, 'longitude': 16.57706, 'id':10},\n",
    "{'name': 'Ebbaelva',      'latitude': 78.70824, 'longitude': 16.599771, 'id':11}\n",
    "]\n",
    "\n",
    "\n",
    "#{'name': 'Endalselva', 'latitude': 78.19590, 'longitude': 15.81446, 'id':2},\n",
    "coords=[{'station': {'station_name': i['name'].strip(),\n",
    "                        'station_id': i['id'],\n",
    "                        'longitude': i['longitude'],\n",
    "                        'latitude': i['latitude'],\n",
    "                        'epsg': 4326,\n",
    "                        'buffer': 75000\n",
    "                       }\n",
    "          } for i in coords\n",
    "       ]\n",
    "\n",
    "with open('adventselva.yaml','w') as f:\n",
    "    f.write(yaml.dump(coords,allow_unicode=True))\n",
    "\n",
    "    \n",
    "def is_number(s):\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False \n",
    "\n",
    "def infoToString(d):\n",
    "    l = [ \"'\"+d[key]+\"'\" if isinstance(d[key],str) else str(d[key])  for key in ['station_name','station_id','longitude','latitude','buffer','epsg','limits']]\n",
    "    return 'row(' + ','.join(l) +')::station_info'\n",
    "\n",
    "def yamlToInfoArray(yamlFile):\n",
    "    allStations = list()\n",
    "    stations = yaml.safe_load(open(yamlFile))\n",
    "    for i in stations:\n",
    "        data = i['station']\n",
    "        if is_number(data['buffer']):\n",
    "            data['limits'] = ''\n",
    "        else:\n",
    "            data['buffer'] = -9999\n",
    "        allStations.append(data)\n",
    "    return 'ARRAY[' +  ','.join([infoToString(i) for i in allStations]) + ']', ' '.join([str(i['station_id']) for i in allStations]);\n",
    "\n",
    "array,ids = yamlToInfoArray('adventselva.yaml')\n",
    "display(array,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " initializestations \n",
      "--------------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      " addstations \n",
      "-------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      " initializeresultsschema \n",
      "-------------------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      " createdatatable \n",
      "-----------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      " createresultstable \n",
      "--------------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      "1\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=1' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.354733\n",
      "Compute time: 1.657022\n",
      "Write time: 1.059067\n",
      "Total time: 6.070822\n",
      "Creating output basin1.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "2\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=2' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.296146\n",
      "Compute time: 1.057842\n",
      "Write time: 1.075480\n",
      "Total time: 5.429468\n",
      "Creating output basin2.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "3\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=3' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.296878\n",
      "Compute time: 1.131604\n",
      "Write time: 1.076751\n",
      "Total time: 5.505233\n",
      "Creating output basin3.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "4\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=4' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.263769\n",
      "Compute time: 1.103840\n",
      "Write time: 1.075500\n",
      "Total time: 5.443109\n",
      "Creating output basin4.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "INSERT 0 1\n",
      "INSERT 0 1\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "5\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=5' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.290307\n",
      "Compute time: 1.082879\n",
      "Write time: 1.080156\n",
      "Total time: 5.453343\n",
      "Creating output basin5.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "6\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=6' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.299330\n",
      "Compute time: 1.675847\n",
      "Write time: 1.062764\n",
      "Total time: 6.037941\n",
      "Creating output basin6.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "7\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=7' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.350984\n",
      "Compute time: 1.199168\n",
      "Write time: 1.078799\n",
      "Total time: 5.628951\n",
      "Creating output basin7.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "8\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=8' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.689988\n",
      "Compute time: 1.192047\n",
      "Write time: 1.078605\n",
      "Total time: 5.960640\n",
      "Creating output basin8.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "9\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=9' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.665487\n",
      "Compute time: 2.127783\n",
      "Write time: 1.077128\n",
      "Total time: 6.870398\n",
      "Creating output basin9.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "INSERT 0 1\n",
      "INSERT 0 1\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "10\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=10' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.705345\n",
      "Compute time: 1.536028\n",
      "Write time: 1.073049\n",
      "Total time: 6.314422\n",
      "Creating output basin10.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "11\n",
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Point\n",
      "Dumping: X [1 rows].\n",
      "Gage Watershed version 5.3.8\n",
      "Input file PG:dbname=geosvalbard schema=test table=flow column=rast where='station_id=11' mode=2 has projected coordinate system.\n",
      "Size: 16\n",
      "Read time: 3.823161\n",
      "Compute time: 1.007019\n",
      "Write time: 0.986092\n",
      "Total time: 5.816272\n",
      "Creating output basin11.shp of format ESRI Shapefile.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "SET\n",
      "SET\n",
      "          dropgeometrycolumn          \n",
      "--------------------------------------\n",
      " test.dummy.geom effectively removed.\n",
      "(1 row)\n",
      "\n",
      "DROP TABLE\n",
      "BEGIN\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "               addgeometrycolumn                \n",
      "------------------------------------------------\n",
      " test.dummy.geom SRID:3035 TYPE:POLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n",
      "INSERT 0 1\n",
      "COMMIT\n",
      "ANALYZE\n",
      "INSERT 0 1\n",
      "DROP TABLE\n",
      "COPY 11\n"
     ]
    }
   ],
   "source": [
    "svalbardScript='''#!/bin/bash\n",
    "#Initializing schema for basin processing\n",
    "read -r -d '' SQL <<- EOM\n",
    "SELECT procedures.initializeStations();\n",
    "SELECT procedures.addStations({2});\n",
    "SELECT procedures.initializeResultsSchema('{0}');\n",
    "SELECT procedures.createDataTable('{0}','dem');\n",
    "SELECT procedures.createResultsTable('{0}','results');\n",
    "EOM\n",
    "echo $SQL | psql -d geosvalbard\n",
    "# Processing basin for station with station_id id     \n",
    "for id in {1}\n",
    "do\n",
    "  echo $id\n",
    "  rm -rf Trash${{id}}\n",
    "  mkdir Trash${{id}}\n",
    "  cd Trash${{id}}\n",
    "\n",
    "  #Exporting outlets from database as a shapefile\n",
    "  pgsql2shp -g outlet -f stations${{id}} geosvalbard \"select station_name, station_id, outlet  from {0}.demshp where station_id=${{id}}\"\n",
    "  \n",
    "  #Computing basing using TauDEM. This produces a boolean tif where true means the cell is upstream of the outlet (i.e. part of the basin)\n",
    "  n=`nproc`\n",
    "  mpiexec -n $n gagewatershed -p \"PG:dbname=geosvalbard schema={0} table=flow column=rast where='station_id=${{id}}' mode=2\" -o stations${{id}}.shp -gw watershed${{id}}.tif\n",
    "\n",
    "  #Transforming upstream pixels to shapefile\n",
    "  gdal_polygonize.py -f \"ESRI Shapefile\" watershed${{id}}.tif basin${{id}}.shp\n",
    "\n",
    "  #Uploading the basin shapefile to the database\n",
    "  shp2pgsql -S -d -s 3035 basin${{id}}.shp {0}.dummy | psql -d geosvalbard   \n",
    "  \n",
    "  #Placing the basin shapefile in the results table    \n",
    "  read -r -d '' SQL <<- EOM\n",
    "      INSERT INTO {0}.resultsShp(station_id,station_name,basin)\n",
    "      SELECT b.station_id, b.station_name, ST_MakeValid(ST_Multi(ST_Union(a.geom)))\n",
    "      FROM {0}.stations AS b, {0}.dummy AS a\n",
    "      WHERE b.station_id=${{id}}\n",
    "      GROUP BY station_id, station_name;\n",
    "EOM\n",
    "  echo $SQL | psql -d geosvalbard\n",
    "\n",
    "  cd $startDir\n",
    "  rm -rf Trash${{id}}\n",
    "done\n",
    "\n",
    "echo \"DROP TABLE IF EXISTS {0}.dummy;\" | psql -d geosvalbard\n",
    "\n",
    "#Getting extent of basin and saving it to a txt file on the server\n",
    "IFS=$'\\\\n' read -r -d '' SQL <<- EOM\n",
    "    (SELECT station_name,Box2D(ST_Transform(St_Buffer(St_Envelope(basin),2000),4326)) FROM {0}.resultsShp)\n",
    "EOM\n",
    "echo \"\\COPY \"$SQL\" TO '/home/jose-luis/results.txt' DELIMITER ';';\" | psql -d geosvalbard\n",
    "'''.format('test',ids,array)\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh', hide='stderr')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE FUNCTION\n"
     ]
    }
   ],
   "source": [
    "svalbardScript='''#! /bin/bash\n",
    "read -r -d '' sql <<-EOM\n",
    "CREATE OR REPLACE FUNCTION procedures.getElevation(_table text,_station text) RETURNS void AS \\$\\$ \n",
    "DECLARE\n",
    "  table_name text := 'test.' || _table;\n",
    "  station  text := _station;\n",
    "BEGIN \n",
    "  EXECUTE 'DROP TABLE IF EXISTS subdivided;';\n",
    "  EXECUTE FORMAT('CREATE TEMP TABLE subdivided AS \n",
    "                  SELECT ST_Subdivide(basin,256) AS geom \n",
    "                  FROM test.resultsshp AS a \n",
    "                  WHERE a.station_name=%s;', \\'\\'\\'\\' || station || \\'\\'\\'\\' );\n",
    "  EXECUTE 'DROP INDEX IF EXISTS subdivided_idx';\n",
    "  EXECUTE 'CREATE INDEX subdivided_idx ON subdivided USING GIST(geom)';\n",
    "  \n",
    "  EXECUTE 'DROP TABLE IF EXISTS elevData';\n",
    "  EXECUTE FORMAT('CREATE TEMP TABLE elevData AS \n",
    "                  SELECT ST_DumpAsPolygons(rast) AS geo \n",
    "                  FROM test.resultsshp AS a, svalbard.el as b \n",
    "                  WHERE ST_Intersects(b.extent,a.basin) \n",
    "                  AND a.station_name=%s',\\'\\'\\'\\' || station || \\'\\'\\'\\');\n",
    "  EXECUTE 'DROP INDEX IF EXISTS elevData_idx;';\n",
    "  EXECUTE 'CREATE INDEX elevData_idx ON elevData USING GIST(((elevData.geo).geom));';\n",
    "  \n",
    "  EXECUTE FORMAT('DROP TABLE IF EXISTS %s;',table_name);\n",
    "  EXECUTE FORMAT('CREATE TABLE %s(id SERIAL PRIMARY KEY, elev DOUBLE PRECISION, geom GEOMETRY(POLYGON,3035));', table_name);\n",
    "  EXECUTE FORMAT('INSERT INTO %s(elev,geom) \n",
    "                  SELECT DISTINCT (a.geo).val, (a.geo).geom \n",
    "                  FROM elevData AS a, subdivided AS b \n",
    "                  WHERE ST_Intersects(b.geom,(a.geo).geom);', table_name);\n",
    "  \n",
    "  EXECUTE 'DROP TABLE IF EXISTS toRemove;';\n",
    "  EXECUTE 'CREATE TEMP TABLE toRemove(id INTEGER, geom GEOMETRY(POLYGON,3035));';\n",
    "  EXECUTE FORMAT('WITH myLine AS (SELECT ST_Boundary(basin) AS geom FROM test.resultsshp AS a WHERE a.station_name=%s) \n",
    "                  INSERT INTO toRemove(id,geom)\n",
    "                  SELECT a.id,a.geom \n",
    "                  FROM %s AS a, myLine AS b\n",
    "                  WHERE ST_Intersects(a.geom,b.geom);', \\'\\'\\'\\' || station || \\'\\'\\'\\', table_name);\n",
    "  \n",
    "  EXECUTE 'DROP TABLE IF EXISTS intersections;';\n",
    "  EXECUTE 'CREATE TEMP TABLE intersections AS\n",
    "           SELECT a.id, SUM(ST_Area(ST_Intersection(a.geom,b.geom))) AS suma\n",
    "           FROM subdivided AS b, toRemove AS a\n",
    "           WHERE ST_Intersects(a.geom,b.geom)\n",
    "           GROUP by a.id;';\n",
    "  \n",
    "  EXECUTE FORMAT('DELETE FROM %s AS A USING intersections AS b WHERE a.id=b.id AND b.suma < 0.1;', table_name);\n",
    "  \n",
    "  RETURN;\n",
    "END;\n",
    "\\$\\$ LANGUAGE PLPGSQL;\n",
    "EOM\n",
    "\n",
    "echo $sql | psql -d geosvalbard\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"adventelvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"endalselvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"todalselvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"bolterelvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"foxelvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"adventelvaseaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"degeerelvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"sassenelvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"sassenelvaseaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"gipsdalselvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n",
      "NOTICE:  table \"subdivided\" does not exist, skipping\n",
      "NOTICE:  index \"subdivided_idx\" does not exist, skipping\n",
      "NOTICE:  table \"elevdata\" does not exist, skipping\n",
      "WARNING:  Unknown GDAL driver: enable_all\n",
      "NOTICE:  index \"elevdata_idx\" does not exist, skipping\n",
      "NOTICE:  table \"ebbaelvaelev\" does not exist, skipping\n",
      "NOTICE:  table \"toremove\" does not exist, skipping\n",
      "NOTICE:  table \"intersections\" does not exist, skipping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adventelva</th>\n",
       "      <th>Endalselva</th>\n",
       "      <th>Todalselva</th>\n",
       "      <th>Bolterelva</th>\n",
       "      <th>Foxelva</th>\n",
       "      <th>AdventelvaSea</th>\n",
       "      <th>DeGeerelva</th>\n",
       "      <th>Sassenelva</th>\n",
       "      <th>SassenelvaSea</th>\n",
       "      <th>Gipsdalselva</th>\n",
       "      <th>Ebbaelva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.079158e+06</td>\n",
       "      <td>77331.000000</td>\n",
       "      <td>90592.000000</td>\n",
       "      <td>92943.000000</td>\n",
       "      <td>64714.000000</td>\n",
       "      <td>1.280957e+06</td>\n",
       "      <td>204311.000000</td>\n",
       "      <td>22857.000000</td>\n",
       "      <td>1.825019e+06</td>\n",
       "      <td>578839.000000</td>\n",
       "      <td>137854.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.393804e+02</td>\n",
       "      <td>452.164753</td>\n",
       "      <td>484.637470</td>\n",
       "      <td>508.335654</td>\n",
       "      <td>546.297248</td>\n",
       "      <td>4.335712e+02</td>\n",
       "      <td>412.128910</td>\n",
       "      <td>76.982761</td>\n",
       "      <td>3.430105e+02</td>\n",
       "      <td>386.728876</td>\n",
       "      <td>504.494462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.500534e+02</td>\n",
       "      <td>239.056164</td>\n",
       "      <td>204.604542</td>\n",
       "      <td>205.193617</td>\n",
       "      <td>206.496521</td>\n",
       "      <td>2.532794e+02</td>\n",
       "      <td>217.572433</td>\n",
       "      <td>97.399792</td>\n",
       "      <td>2.226645e+02</td>\n",
       "      <td>262.005384</td>\n",
       "      <td>258.190201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.224963e+00</td>\n",
       "      <td>3.983034</td>\n",
       "      <td>49.152260</td>\n",
       "      <td>56.953365</td>\n",
       "      <td>98.371750</td>\n",
       "      <td>7.024645e-01</td>\n",
       "      <td>9.694341</td>\n",
       "      <td>0.516186</td>\n",
       "      <td>5.108159e-01</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>0.439645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.226992e+02</td>\n",
       "      <td>270.084702</td>\n",
       "      <td>351.762215</td>\n",
       "      <td>363.802490</td>\n",
       "      <td>393.475090</td>\n",
       "      <td>2.156571e+02</td>\n",
       "      <td>234.671982</td>\n",
       "      <td>3.109151</td>\n",
       "      <td>1.333124e+02</td>\n",
       "      <td>131.576912</td>\n",
       "      <td>325.537239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.483418e+02</td>\n",
       "      <td>478.571259</td>\n",
       "      <td>500.938812</td>\n",
       "      <td>527.569885</td>\n",
       "      <td>562.466034</td>\n",
       "      <td>4.457000e+02</td>\n",
       "      <td>404.384613</td>\n",
       "      <td>24.780209</td>\n",
       "      <td>3.652377e+02</td>\n",
       "      <td>396.914703</td>\n",
       "      <td>556.465576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.376409e+02</td>\n",
       "      <td>610.771790</td>\n",
       "      <td>603.768387</td>\n",
       "      <td>669.581848</td>\n",
       "      <td>717.590591</td>\n",
       "      <td>6.318264e+02</td>\n",
       "      <td>570.898193</td>\n",
       "      <td>157.143204</td>\n",
       "      <td>5.276397e+02</td>\n",
       "      <td>593.961700</td>\n",
       "      <td>692.780731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.143694e+03</td>\n",
       "      <td>1020.984863</td>\n",
       "      <td>1021.318420</td>\n",
       "      <td>966.332947</td>\n",
       "      <td>1012.748657</td>\n",
       "      <td>1.143694e+03</td>\n",
       "      <td>991.560669</td>\n",
       "      <td>477.400085</td>\n",
       "      <td>9.335325e+02</td>\n",
       "      <td>1117.072998</td>\n",
       "      <td>1119.646973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Adventelva    Endalselva    Todalselva    Bolterelva       Foxelva  \\\n",
       "count  1.079158e+06  77331.000000  90592.000000  92943.000000  64714.000000   \n",
       "mean   4.393804e+02    452.164753    484.637470    508.335654    546.297248   \n",
       "std    2.500534e+02    239.056164    204.604542    205.193617    206.496521   \n",
       "min    3.224963e+00      3.983034     49.152260     56.953365     98.371750   \n",
       "25%    2.226992e+02    270.084702    351.762215    363.802490    393.475090   \n",
       "50%    4.483418e+02    478.571259    500.938812    527.569885    562.466034   \n",
       "75%    6.376409e+02    610.771790    603.768387    669.581848    717.590591   \n",
       "max    1.143694e+03   1020.984863   1021.318420    966.332947   1012.748657   \n",
       "\n",
       "       AdventelvaSea     DeGeerelva    Sassenelva  SassenelvaSea  \\\n",
       "count   1.280957e+06  204311.000000  22857.000000   1.825019e+06   \n",
       "mean    4.335712e+02     412.128910     76.982761   3.430105e+02   \n",
       "std     2.532794e+02     217.572433     97.399792   2.226645e+02   \n",
       "min     7.024645e-01       9.694341      0.516186   5.108159e-01   \n",
       "25%     2.156571e+02     234.671982      3.109151   1.333124e+02   \n",
       "50%     4.457000e+02     404.384613     24.780209   3.652377e+02   \n",
       "75%     6.318264e+02     570.898193    157.143204   5.276397e+02   \n",
       "max     1.143694e+03     991.560669    477.400085   9.335325e+02   \n",
       "\n",
       "        Gipsdalselva       Ebbaelva  \n",
       "count  578839.000000  137854.000000  \n",
       "mean      386.728876     504.494462  \n",
       "std       262.005384     258.190201  \n",
       "min         0.902945       0.439645  \n",
       "25%       131.576912     325.537239  \n",
       "50%       396.914703     556.465576  \n",
       "75%       593.961700     692.780731  \n",
       "max      1117.072998    1119.646973  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "stations = yaml.safe_load(open('adventselva.yaml'))\n",
    "def cdf(x, plot=True, *args, **kwargs):\n",
    "    x, y = (sorted(x) - min(x)) / (max(x) - min(x)), np.arange(len(x)) / len(x)\n",
    "    #plt.plot(y, x, *args, **kwargs) if plot else (x, y)\n",
    "    #plt.xlim([1.01,-0.01])\n",
    "    return x,y\n",
    "\n",
    "def getElevation(table,station):\n",
    "    svalbardScript='''#! /bin/bash\n",
    "echo \"SELECT procedures.getElevation(\\'{0}\\',\\'{1}\\');\" | psql -d geosvalbard\n",
    "echo \"\\COPY (SELECT elev from test.{0}) TO \\'/home/jose-luis/dummy.txt\\' DELIMITER \\',\\';\" | psql -d geosvalbard\n",
    "'''.format(table,station)\n",
    "   \n",
    "    with open('script.sh','w') as bla:\n",
    "        bla.write(svalbardScript)\n",
    "    with Connection(host=basin.properties['ip'],\n",
    "                   user=basin.properties['username'],\n",
    "                   connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                   ) as c:\n",
    "        c.put('script.sh')\n",
    "        c.run('chmod +x script.sh')\n",
    "        c.run('./script.sh',hide='stderr')\n",
    "        #c.run('rm script.sh')\n",
    "        c.get('dummy.txt')\n",
    "    elevation = pd.read_csv('dummy.txt'.format(station), header=None, names=['Elevation',])\n",
    "    return elevation\n",
    "\n",
    "cnt = False\n",
    "ecdf = dict()\n",
    "for i in stations:\n",
    "    station = i['station']['station_name']\n",
    "    elevation = getElevation(station + 'Elev',station)   \n",
    "    x,y=cdf(elevation.Elevation.values)\n",
    "    ecdf[station]= {'x': x, 'y': y}\n",
    "    elevation.rename(columns={'Elevation':station},inplace=True)\n",
    "    if not cnt:\n",
    "        info = elevation.describe()\n",
    "        cnt = True\n",
    "    else:\n",
    "        dummy = elevation.describe()\n",
    "        info = pd.concat([info, dummy], axis=1, join='inner')\n",
    "\n",
    "        \n",
    "display(info)\n",
    "info.to_csv('elevationInfo.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "for key, values in ecdf.items(): \n",
    "    plt.plot(values['y'],values['x'],label=key)\n",
    "    \n",
    "plt.xlim([1.01,-0.01])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig('hypsogram.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e655a98dfc3496cbaf79ef451c3b9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = query('''SELECT json_build_object('type', 'FeatureCollection',\n",
    "                                      'features', json_agg(json_build_object(\n",
    "                                                                'type',       'Feature',\n",
    "                                                                'label',      station_name,\n",
    "                                                                'geometry',   ST_AsGeoJSON(ST_ForceRHR(St_Transform(basin,4326)))::json,\n",
    "                                                                'properties', jsonb_set(row_to_json(resultsShp)::jsonb,'{basin}','0',false)\n",
    "                                                                )\n",
    "                                                            )\n",
    "                                     )\n",
    "             FROM test.resultsShp;''')\n",
    "\n",
    "fig = gmaps.figure(map_type=\"TERRAIN\")\n",
    "fig.add_layer(gmaps.geojson_layer(a[0][0]))\n",
    "\n",
    "b = query('''SELECT a.station_name, st_x(st_transform(a.outlet,4326)),\n",
    "    st_y(st_transform(a.outlet,4326)), st_area(b.basin)/1e6\n",
    "    FROM test.demShp AS a\n",
    "    INNER JOIN test.resultsShp AS b \n",
    "    ON a.station_id = b.station_id''')\n",
    "\n",
    "outlets = [{\"name\": i[0], \"area\": i[3]} for i in b]\n",
    "locations = [(float(i[2]),float(i[1])) for i in b]\n",
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<font color=\"black\">\n",
    "<dt>Name</dt><dd>{name}</dd>\n",
    "<dt>Area</dt><dd>{area} km<sup>2</sup></dd>\n",
    "</font>\n",
    "</dl>\n",
    "\"\"\"                                                \n",
    "outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "marker_layer = gmaps.marker_layer(locations, info_box_content=outlet_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing... \n",
      "Done (postgis major version: 2).\n",
      "Output shape: Polygon\n",
      "Dumping: X [11 rows].\n"
     ]
    }
   ],
   "source": [
    "svalbardScript='''#! /bin/bash\n",
    "pgsql2shp -f \"./svalbard_basins.shp\" -h localhost geosvalbard \"SELECT *, st_area(basin) as  basinArea FROM test.resultsshp;\"\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh')\n",
    "    c.run('tar -cf  svalbardShp.tar svalbard_basins.*')\n",
    "    c.get('svalbardShp.tar')\n",
    "    c.run('rm svalbard_basins*')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersecting glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shapefile type: PolygonZ\n",
      "Postgis type: POLYGON[4]\n",
      "ERROR:  column not found in geometry_columns table\n",
      "CONTEXT:  PL/pgSQL function dropgeometrycolumn(character varying,character varying,character varying,character varying) line 34 at RAISE\n",
      "SQL statement \"SELECT DropGeometryColumn('',$1,$2,$3)\"\n",
      "PL/pgSQL function dropgeometrycolumn(character varying,character varying,character varying) line 5 at SQL statement\n",
      "NOTICE:  table \"glaciers\" does not exist, skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 addgeometrycolumn                 \n",
      "---------------------------------------------------\n",
      " test.glaciers.geom SRID:3035 TYPE:POLYGON DIMS:4 \n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Connection('localhost') as c:\n",
    "    c.local('cp /home/jose-luis/Envs/niva_prognos/PROGNOS/notebooks/createGeodatabase/Shapefiles/NP_S100_SHP/S100_Isbreer_f.* .')\n",
    "    c.local('tar -cf glaciers.tar S100_Isbreer_f.*')\n",
    "    c.local('rm -r ./S100_Isbreer_f.*')\n",
    "\n",
    "\n",
    "svalbardScript='''#! /bin/bash\n",
    "shp2pgsql -I -s 32633:3035 -S -W \"LATIN1\"  -d S100_Isbreer_f.shp test.glaciers | psql -q -d geosvalbard\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.put('glaciers.tar')\n",
    "    c.run('tar -xf glaciers.tar')\n",
    "    c.run('rm glaciers.tar')\n",
    "    c.run('./script.sh')\n",
    "    #c.run('tar -cf  svalbardShp.tar S100_Isbreer_f.*')\n",
    "    c.run('rm S100_Isbreer_f.*')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query(\"CREATE INDEX basins_idx ON test.resultsshp USING GIST(basin);\",fetch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ebbaelva', 28.1945882277367, 54.8167380951996, 51.4342684505808),\n",
       " ('Endalselva', 4.24358132687086, 30.7312759240085, 13.8086727585417),\n",
       " ('AdventelvaSea', 95.9645529638512, 510.488696498593, 18.7985656924562),\n",
       " ('Foxelva', 8.68756054858029, 25.7182064887003, 33.7798071276755),\n",
       " ('SassenelvaSea', 195.324008319055, 725.508685806743, 26.9223528456949),\n",
       " ('Todalselva', 3.73765231976206, 36.004217538349, 10.3811513631174),\n",
       " ('Gipsdalselva', 40.6649097931255, 230.132708857379, 17.6701999446445),\n",
       " ('DeGeerelva', 8.38424196845165, 81.1945589832831, 10.3261130714163),\n",
       " ('Bolterelva', 7.87480665634056, 37.0119176087329, 21.2764081547683),\n",
       " ('Adventelva', 87.1195915960227, 428.961151451043, 20.3094362511206)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(query('''CREATE TEMP TABLE dummy AS SELECT a.gid,b.station_name,st_intersection(a.geom,b.basin) as glacierCover\n",
    "FROM test.glaciers AS a, test.resultsshp AS b WHERE ST_Intersects(a.geom,b.basin);\n",
    "CREATE TEMP TABLE dummy_accum AS SELECT c.station_name,sum(st_area(c.glacierCover))/1e6 as glacierArea FROM dummy AS c\n",
    "GROUP BY station_name;\n",
    "SELECT a.station_name, a.glacierArea, st_area(b.basin)/1e6, a.glacierArea/(st_area(b.basin)/1e6) * 100 FROM dummy_accum AS a\n",
    "INNER JOIN test.resultsshp as b\n",
    "ON a.station_name = b.station_name;\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shapefile type: Polygon\n",
      "Postgis type: MULTIPOLYGON[2]\n",
      "ERROR:  column not found in geometry_columns table\n",
      "CONTEXT:  PL/pgSQL function dropgeometrycolumn(character varying,character varying,character varying,character varying) line 34 at RAISE\n",
      "SQL statement \"SELECT DropGeometryColumn('',$1,$2,$3)\"\n",
      "PL/pgSQL function dropgeometrycolumn(character varying,character varying,character varying) line 5 at SQL statement\n",
      "NOTICE:  table \"geology\" does not exist, skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   addgeometrycolumn                   \n",
      "-------------------------------------------------------\n",
      " test.geology.geom SRID:3035 TYPE:MULTIPOLYGON DIMS:2 \n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Connection('localhost') as c:\n",
    "    c.local('cp /home/jose-luis/Envs/niva_prognos/PROGNOS/notebooks/createGeodatabase/Shapefiles/Geology_data/Svalbard_Geology_G250/G250_Shape_files/g250_Geology.* .')\n",
    "    c.local('tar -cf geology.tar g250_Geology.*')\n",
    "    c.local('rm -r ./g250_Geology.*')\n",
    "\n",
    "\n",
    "svalbardScript='''#! /bin/bash\n",
    "shp2pgsql -I -s 32633:3035 -W \"LATIN1\"  -d g250_Geology.shp test.geology | psql -q -d geosvalbard\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.put('geology.tar')\n",
    "    c.run('tar -xf geology.tar')\n",
    "    c.run('rm geology.tar')\n",
    "    c.run('./script.sh')\n",
    "    c.run('rm g250_Geology.*')\n",
    "    c.run('rm script.sh')\n",
    "    \n",
    "#query(\"CREATE INDEX geology_idx ON test.geology USING GIST(geom);\",fetch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>main_litho</th>\n",
       "      <th>area(km2)</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>sandstone, siltstone, mudstone</td>\n",
       "      <td>3.482634</td>\n",
       "      <td>0.811876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>marine deposit</td>\n",
       "      <td>3.667394</td>\n",
       "      <td>0.854948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>sandstone, siltstone, shale</td>\n",
       "      <td>4.791403</td>\n",
       "      <td>1.116978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>sandstone, shale, mudstone, conglomerate</td>\n",
       "      <td>7.173016</td>\n",
       "      <td>1.672183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>shale, mudstone, siltstone</td>\n",
       "      <td>9.213427</td>\n",
       "      <td>2.147847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>shale, sandstone</td>\n",
       "      <td>13.164291</td>\n",
       "      <td>3.068877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>moraine</td>\n",
       "      <td>16.269962</td>\n",
       "      <td>3.792875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>sandstone, shale, coal</td>\n",
       "      <td>16.687749</td>\n",
       "      <td>3.890270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>sandstone, conglomerate</td>\n",
       "      <td>23.633154</td>\n",
       "      <td>5.509393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>31.031797</td>\n",
       "      <td>7.234174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>glaci-fluvial deposit</td>\n",
       "      <td>34.461136</td>\n",
       "      <td>8.033626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>shale (bituminous), siltstone</td>\n",
       "      <td>34.594942</td>\n",
       "      <td>8.064819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>dark shale, siltstone, sandstone</td>\n",
       "      <td>48.598924</td>\n",
       "      <td>11.329447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adventelva</td>\n",
       "      <td>shale, siltstone, sandstone</td>\n",
       "      <td>88.684704</td>\n",
       "      <td>20.674297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>sandstone, siltstone, mudstone</td>\n",
       "      <td>5.004270</td>\n",
       "      <td>0.980290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>sandstone, siltstone, shale</td>\n",
       "      <td>6.570001</td>\n",
       "      <td>1.287002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>marine deposit</td>\n",
       "      <td>6.991839</td>\n",
       "      <td>1.369636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>sandstone, shale, mudstone, conglomerate</td>\n",
       "      <td>7.173016</td>\n",
       "      <td>1.405127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>shale, mudstone, siltstone</td>\n",
       "      <td>13.507733</td>\n",
       "      <td>2.646040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>shale, sandstone</td>\n",
       "      <td>16.087172</td>\n",
       "      <td>3.151328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>moraine</td>\n",
       "      <td>18.484838</td>\n",
       "      <td>3.621008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>sandstone, shale, coal</td>\n",
       "      <td>23.434086</td>\n",
       "      <td>4.590520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>sandstone, conglomerate</td>\n",
       "      <td>27.415032</td>\n",
       "      <td>5.370350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>shale (bituminous), siltstone</td>\n",
       "      <td>34.594942</td>\n",
       "      <td>6.776828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>41.908711</td>\n",
       "      <td>8.209528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>glaci-fluvial deposit</td>\n",
       "      <td>46.076108</td>\n",
       "      <td>9.025882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>dark shale, siltstone, sandstone</td>\n",
       "      <td>50.364859</td>\n",
       "      <td>9.866009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdventelvaSea</td>\n",
       "      <td>shale, siltstone, sandstone</td>\n",
       "      <td>108.898244</td>\n",
       "      <td>21.332156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bolterelva</td>\n",
       "      <td>glaci-fluvial deposit</td>\n",
       "      <td>0.927851</td>\n",
       "      <td>2.506899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bolterelva</td>\n",
       "      <td>sandstone, siltstone, mudstone</td>\n",
       "      <td>0.992490</td>\n",
       "      <td>2.681543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Gipsdalselva</td>\n",
       "      <td>dolomite, sandstone, gypsum</td>\n",
       "      <td>21.670203</td>\n",
       "      <td>9.416394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Gipsdalselva</td>\n",
       "      <td>glaci-fluvial deposit</td>\n",
       "      <td>27.945149</td>\n",
       "      <td>12.143058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Gipsdalselva</td>\n",
       "      <td>carbonate rocks</td>\n",
       "      <td>35.514719</td>\n",
       "      <td>15.432278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Gipsdalselva</td>\n",
       "      <td>dolomite, limest., anhydrite/gypsum, carb. bre...</td>\n",
       "      <td>37.267102</td>\n",
       "      <td>16.193744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Sassenelva</td>\n",
       "      <td>mudstone (bituminous), calcareous siltstone</td>\n",
       "      <td>0.025851</td>\n",
       "      <td>0.284628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sassenelva</td>\n",
       "      <td>shale, siltstone</td>\n",
       "      <td>1.341856</td>\n",
       "      <td>14.774221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Sassenelva</td>\n",
       "      <td>chert, siliceous shale, sandstone, limestone</td>\n",
       "      <td>3.129161</td>\n",
       "      <td>34.452969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Sassenelva</td>\n",
       "      <td>marine deposit</td>\n",
       "      <td>4.585545</td>\n",
       "      <td>50.488183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>dolomite, limest., anhydrite/gypsum, carb. bre...</td>\n",
       "      <td>2.431513</td>\n",
       "      <td>0.335146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>sandstone, conglomerate</td>\n",
       "      <td>4.412654</td>\n",
       "      <td>0.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>dark shale, siltstone, sandstone</td>\n",
       "      <td>4.799121</td>\n",
       "      <td>0.661484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>shale (bituminous), siltstone</td>\n",
       "      <td>7.061360</td>\n",
       "      <td>0.973298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>dolerite</td>\n",
       "      <td>8.836485</td>\n",
       "      <td>1.217971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>sandstone, shale, mudstone, conglomerate</td>\n",
       "      <td>10.261243</td>\n",
       "      <td>1.414351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>moraine</td>\n",
       "      <td>17.083064</td>\n",
       "      <td>2.354633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>marine deposit</td>\n",
       "      <td>39.872257</td>\n",
       "      <td>5.495766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>mudstone (bituminous), calcareous siltstone</td>\n",
       "      <td>47.791920</td>\n",
       "      <td>6.587367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>shale, siltstone</td>\n",
       "      <td>76.019051</td>\n",
       "      <td>10.478035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>glaci-fluvial deposit</td>\n",
       "      <td>83.741810</td>\n",
       "      <td>11.542496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>shale, siltstone, sandstone</td>\n",
       "      <td>88.347252</td>\n",
       "      <td>12.177284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>SassenelvaSea</td>\n",
       "      <td>chert, siliceous shale, sandstone, limestone</td>\n",
       "      <td>129.675423</td>\n",
       "      <td>17.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>moraine</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>0.568850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>glaci-fluvial deposit</td>\n",
       "      <td>0.695951</td>\n",
       "      <td>1.932970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>shale, mudstone, siltstone</td>\n",
       "      <td>2.002303</td>\n",
       "      <td>5.561302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>shale, siltstone, sandstone</td>\n",
       "      <td>2.358302</td>\n",
       "      <td>6.550072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>sandstone, siltstone, shale</td>\n",
       "      <td>2.456530</td>\n",
       "      <td>6.822894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>sandstone, siltstone, mudstone</td>\n",
       "      <td>2.479292</td>\n",
       "      <td>6.886115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>sandstone, shale, coal</td>\n",
       "      <td>2.564433</td>\n",
       "      <td>7.122589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>shale, sandstone</td>\n",
       "      <td>8.770216</td>\n",
       "      <td>24.358859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Todalselva</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>9.842806</td>\n",
       "      <td>27.337924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_name                                         main_litho  \\\n",
       "0       Adventelva                     sandstone, siltstone, mudstone   \n",
       "1       Adventelva                                     marine deposit   \n",
       "2       Adventelva                        sandstone, siltstone, shale   \n",
       "3       Adventelva           sandstone, shale, mudstone, conglomerate   \n",
       "4       Adventelva                         shale, mudstone, siltstone   \n",
       "5       Adventelva                                   shale, sandstone   \n",
       "6       Adventelva                                            moraine   \n",
       "7       Adventelva                             sandstone, shale, coal   \n",
       "8       Adventelva                            sandstone, conglomerate   \n",
       "9       Adventelva                                          sandstone   \n",
       "10      Adventelva                              glaci-fluvial deposit   \n",
       "11      Adventelva                      shale (bituminous), siltstone   \n",
       "12      Adventelva                   dark shale, siltstone, sandstone   \n",
       "13      Adventelva                        shale, siltstone, sandstone   \n",
       "14   AdventelvaSea                     sandstone, siltstone, mudstone   \n",
       "15   AdventelvaSea                        sandstone, siltstone, shale   \n",
       "16   AdventelvaSea                                     marine deposit   \n",
       "17   AdventelvaSea           sandstone, shale, mudstone, conglomerate   \n",
       "18   AdventelvaSea                         shale, mudstone, siltstone   \n",
       "19   AdventelvaSea                                   shale, sandstone   \n",
       "20   AdventelvaSea                                            moraine   \n",
       "21   AdventelvaSea                             sandstone, shale, coal   \n",
       "22   AdventelvaSea                            sandstone, conglomerate   \n",
       "23   AdventelvaSea                      shale (bituminous), siltstone   \n",
       "24   AdventelvaSea                                          sandstone   \n",
       "25   AdventelvaSea                              glaci-fluvial deposit   \n",
       "26   AdventelvaSea                   dark shale, siltstone, sandstone   \n",
       "27   AdventelvaSea                        shale, siltstone, sandstone   \n",
       "28      Bolterelva                              glaci-fluvial deposit   \n",
       "29      Bolterelva                     sandstone, siltstone, mudstone   \n",
       "..             ...                                                ...   \n",
       "84    Gipsdalselva                        dolomite, sandstone, gypsum   \n",
       "85    Gipsdalselva                              glaci-fluvial deposit   \n",
       "86    Gipsdalselva                                    carbonate rocks   \n",
       "87    Gipsdalselva  dolomite, limest., anhydrite/gypsum, carb. bre...   \n",
       "88      Sassenelva        mudstone (bituminous), calcareous siltstone   \n",
       "89      Sassenelva                                   shale, siltstone   \n",
       "90      Sassenelva       chert, siliceous shale, sandstone, limestone   \n",
       "91      Sassenelva                                     marine deposit   \n",
       "92   SassenelvaSea  dolomite, limest., anhydrite/gypsum, carb. bre...   \n",
       "93   SassenelvaSea                            sandstone, conglomerate   \n",
       "94   SassenelvaSea                   dark shale, siltstone, sandstone   \n",
       "95   SassenelvaSea                      shale (bituminous), siltstone   \n",
       "96   SassenelvaSea                                           dolerite   \n",
       "97   SassenelvaSea           sandstone, shale, mudstone, conglomerate   \n",
       "98   SassenelvaSea                                            moraine   \n",
       "99   SassenelvaSea                                     marine deposit   \n",
       "100  SassenelvaSea        mudstone (bituminous), calcareous siltstone   \n",
       "101  SassenelvaSea                                   shale, siltstone   \n",
       "102  SassenelvaSea                              glaci-fluvial deposit   \n",
       "103  SassenelvaSea                        shale, siltstone, sandstone   \n",
       "104  SassenelvaSea       chert, siliceous shale, sandstone, limestone   \n",
       "105     Todalselva                                            moraine   \n",
       "106     Todalselva                              glaci-fluvial deposit   \n",
       "107     Todalselva                         shale, mudstone, siltstone   \n",
       "108     Todalselva                        shale, siltstone, sandstone   \n",
       "109     Todalselva                        sandstone, siltstone, shale   \n",
       "110     Todalselva                     sandstone, siltstone, mudstone   \n",
       "111     Todalselva                             sandstone, shale, coal   \n",
       "112     Todalselva                                   shale, sandstone   \n",
       "113     Todalselva                                          sandstone   \n",
       "\n",
       "      area(km2)  percentage  \n",
       "0      3.482634    0.811876  \n",
       "1      3.667394    0.854948  \n",
       "2      4.791403    1.116978  \n",
       "3      7.173016    1.672183  \n",
       "4      9.213427    2.147847  \n",
       "5     13.164291    3.068877  \n",
       "6     16.269962    3.792875  \n",
       "7     16.687749    3.890270  \n",
       "8     23.633154    5.509393  \n",
       "9     31.031797    7.234174  \n",
       "10    34.461136    8.033626  \n",
       "11    34.594942    8.064819  \n",
       "12    48.598924   11.329447  \n",
       "13    88.684704   20.674297  \n",
       "14     5.004270    0.980290  \n",
       "15     6.570001    1.287002  \n",
       "16     6.991839    1.369636  \n",
       "17     7.173016    1.405127  \n",
       "18    13.507733    2.646040  \n",
       "19    16.087172    3.151328  \n",
       "20    18.484838    3.621008  \n",
       "21    23.434086    4.590520  \n",
       "22    27.415032    5.370350  \n",
       "23    34.594942    6.776828  \n",
       "24    41.908711    8.209528  \n",
       "25    46.076108    9.025882  \n",
       "26    50.364859    9.866009  \n",
       "27   108.898244   21.332156  \n",
       "28     0.927851    2.506899  \n",
       "29     0.992490    2.681543  \n",
       "..          ...         ...  \n",
       "84    21.670203    9.416394  \n",
       "85    27.945149   12.143058  \n",
       "86    35.514719   15.432278  \n",
       "87    37.267102   16.193744  \n",
       "88     0.025851    0.284628  \n",
       "89     1.341856   14.774221  \n",
       "90     3.129161   34.452969  \n",
       "91     4.585545   50.488183  \n",
       "92     2.431513    0.335146  \n",
       "93     4.412654    0.608215  \n",
       "94     4.799121    0.661484  \n",
       "95     7.061360    0.973298  \n",
       "96     8.836485    1.217971  \n",
       "97    10.261243    1.414351  \n",
       "98    17.083064    2.354633  \n",
       "99    39.872257    5.495766  \n",
       "100   47.791920    6.587367  \n",
       "101   76.019051   10.478035  \n",
       "102   83.741810   11.542496  \n",
       "103   88.347252   12.177284  \n",
       "104  129.675423   17.873724  \n",
       "105    0.204810    0.568850  \n",
       "106    0.695951    1.932970  \n",
       "107    2.002303    5.561302  \n",
       "108    2.358302    6.550072  \n",
       "109    2.456530    6.822894  \n",
       "110    2.479292    6.886115  \n",
       "111    2.564433    7.122589  \n",
       "112    8.770216   24.358859  \n",
       "113    9.842806   27.337924  \n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = query('''CREATE TEMP TABLE dummy AS SELECT a.main_litho,b.station_name,st_intersection(a.geom,b.basin) as geologyCover\n",
    "FROM test.geology AS a, test.resultsshp AS b WHERE ST_Intersects(a.geom,b.basin);\n",
    "CREATE TEMP TABLE dummy_accum AS SELECT c.station_name,c.main_litho,sum(st_area(c.geologyCover))/1e6 as geologyArea FROM dummy AS c\n",
    "GROUP BY station_name, main_litho\n",
    "ORDER BY station_name,geologyArea;\n",
    "SELECT a.station_name, a.main_litho, a.geologyArea, a.geologyArea/(st_area(b.basin)/1e6) * 100 FROM dummy_accum AS a\n",
    "INNER JOIN test.resultsshp as b\n",
    "ON a.station_name = b.station_name;\n",
    "''')\n",
    "\n",
    "name = [i[0] for i in a]\n",
    "main_litho = [i[1] for i in a]\n",
    "area = [i[2] for i in a]\n",
    "percentage = [i[3] for i in a]\n",
    "\n",
    "data = [name,main_litho,area,percentage]\n",
    "\n",
    "data =  pd.DataFrame({'station_name' : name,'main_litho' :  main_litho, 'area(km2)' : area, 'percentage' : percentage})\n",
    "display(data)\n",
    "data.to_csv('geology.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "svalbardScript='''#! /bin/bash\n",
    "rm -rf slope.tif\n",
    "gdaldem slope svalbard20_3035_subset.tif slope.tif -zero_for_flat\n",
    "raster2pgsql -I -M -F -b 1 -r -s 3035 -d -t auto slope.tif  svalbard.slope | psql -q -d geosvalbard\n",
    "'''\n",
    "\n",
    "with open('script.sh','w') as bla:\n",
    "    bla.write(svalbardScript)\n",
    "with Connection(host=basin.properties['ip'],\n",
    "                       user=basin.properties['username'],\n",
    "                       connect_kwargs={\"key_filename\": basin.properties['keyFile']},\n",
    "                       ) as c:\n",
    "    c.put('script.sh')\n",
    "    c.run('chmod +x script.sh')\n",
    "    c.run('./script.sh', hide='stderr')\n",
    "    c.run('rm script.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"SELECT procedures.setExtentTable('svalbard','slope');\",fetch=False);  #todo: looks like this only works as user postgres\n",
    "display(query('''select * from svalbard.slope where false;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adventelva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Endalselva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Todalselva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Bolterelva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Foxelva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AdventelvaSea'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'DeGeerelva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Sassenelva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'SassenelvaSea'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Gipsdalselva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ebbaelva'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adventelva</th>\n",
       "      <th>Endalselva</th>\n",
       "      <th>Todalselva</th>\n",
       "      <th>Bolterelva</th>\n",
       "      <th>Foxelva</th>\n",
       "      <th>AdventelvaSea</th>\n",
       "      <th>DeGeerelva</th>\n",
       "      <th>Sassenelva</th>\n",
       "      <th>SassenelvaSea</th>\n",
       "      <th>Gipsdalselva</th>\n",
       "      <th>Ebbaelva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.079368e+06</td>\n",
       "      <td>77338.000000</td>\n",
       "      <td>90605.000000</td>\n",
       "      <td>93051.000000</td>\n",
       "      <td>64722.000000</td>\n",
       "      <td>1.281852e+06</td>\n",
       "      <td>204333.000000</td>\n",
       "      <td>22857.000000</td>\n",
       "      <td>1.825690e+06</td>\n",
       "      <td>579092.000000</td>\n",
       "      <td>137946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.539780e+01</td>\n",
       "      <td>16.522654</td>\n",
       "      <td>18.511765</td>\n",
       "      <td>17.524826</td>\n",
       "      <td>18.785330</td>\n",
       "      <td>1.575044e+01</td>\n",
       "      <td>15.632703</td>\n",
       "      <td>6.278237</td>\n",
       "      <td>1.161848e+01</td>\n",
       "      <td>19.544401</td>\n",
       "      <td>14.075467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.085463e+01</td>\n",
       "      <td>11.657729</td>\n",
       "      <td>10.883319</td>\n",
       "      <td>11.529108</td>\n",
       "      <td>11.080920</td>\n",
       "      <td>1.116323e+01</td>\n",
       "      <td>9.720529</td>\n",
       "      <td>8.562740</td>\n",
       "      <td>1.056357e+01</td>\n",
       "      <td>13.483522</td>\n",
       "      <td>11.700644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.048183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099983</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.237889e+00</td>\n",
       "      <td>6.120664</td>\n",
       "      <td>8.784490</td>\n",
       "      <td>7.258502</td>\n",
       "      <td>9.366005</td>\n",
       "      <td>6.221559e+00</td>\n",
       "      <td>7.710014</td>\n",
       "      <td>0.283197</td>\n",
       "      <td>3.306561e+00</td>\n",
       "      <td>6.287843</td>\n",
       "      <td>4.932989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.310797e+01</td>\n",
       "      <td>14.220090</td>\n",
       "      <td>18.177288</td>\n",
       "      <td>15.489082</td>\n",
       "      <td>17.268409</td>\n",
       "      <td>1.349174e+01</td>\n",
       "      <td>14.327744</td>\n",
       "      <td>3.976148</td>\n",
       "      <td>7.900057e+00</td>\n",
       "      <td>19.480540</td>\n",
       "      <td>8.863428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.372712e+01</td>\n",
       "      <td>26.228646</td>\n",
       "      <td>27.238571</td>\n",
       "      <td>27.542756</td>\n",
       "      <td>27.959727</td>\n",
       "      <td>2.468103e+01</td>\n",
       "      <td>22.497789</td>\n",
       "      <td>8.038993</td>\n",
       "      <td>1.796215e+01</td>\n",
       "      <td>31.954687</td>\n",
       "      <td>22.870623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.511977e+01</td>\n",
       "      <td>55.415203</td>\n",
       "      <td>52.058754</td>\n",
       "      <td>52.482899</td>\n",
       "      <td>54.593193</td>\n",
       "      <td>5.720966e+01</td>\n",
       "      <td>46.077187</td>\n",
       "      <td>45.662560</td>\n",
       "      <td>6.376051e+01</td>\n",
       "      <td>64.810524</td>\n",
       "      <td>70.977844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Adventelva    Endalselva    Todalselva    Bolterelva       Foxelva  \\\n",
       "count  1.079368e+06  77338.000000  90605.000000  93051.000000  64722.000000   \n",
       "mean   1.539780e+01     16.522654     18.511765     17.524826     18.785330   \n",
       "std    1.085463e+01     11.657729     10.883319     11.529108     11.080920   \n",
       "min    0.000000e+00      0.006877      0.048183      0.000000      0.099983   \n",
       "25%    6.237889e+00      6.120664      8.784490      7.258502      9.366005   \n",
       "50%    1.310797e+01     14.220090     18.177288     15.489082     17.268409   \n",
       "75%    2.372712e+01     26.228646     27.238571     27.542756     27.959727   \n",
       "max    5.511977e+01     55.415203     52.058754     52.482899     54.593193   \n",
       "\n",
       "       AdventelvaSea     DeGeerelva    Sassenelva  SassenelvaSea  \\\n",
       "count   1.281852e+06  204333.000000  22857.000000   1.825690e+06   \n",
       "mean    1.575044e+01      15.632703      6.278237   1.161848e+01   \n",
       "std     1.116323e+01       9.720529      8.562740   1.056357e+01   \n",
       "min     0.000000e+00       0.008896      0.001473   0.000000e+00   \n",
       "25%     6.221559e+00       7.710014      0.283197   3.306561e+00   \n",
       "50%     1.349174e+01      14.327744      3.976148   7.900057e+00   \n",
       "75%     2.468103e+01      22.497789      8.038993   1.796215e+01   \n",
       "max     5.720966e+01      46.077187     45.662560   6.376051e+01   \n",
       "\n",
       "        Gipsdalselva       Ebbaelva  \n",
       "count  579092.000000  137946.000000  \n",
       "mean       19.544401      14.075467  \n",
       "std        13.483522      11.700644  \n",
       "min         0.000000       0.000000  \n",
       "25%         6.287843       4.932989  \n",
       "50%        19.480540       8.863428  \n",
       "75%        31.954687      22.870623  \n",
       "max        64.810524      70.977844  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stations = [i[0] for i in query(\"select station_name from test.resultsshp;\")]\n",
    "\n",
    "queryStr = '''CREATE TEMP TABLE subdivided AS \n",
    "SELECT ST_Subdivide(basin,256) AS geom \n",
    "FROM test.resultsshp AS a \n",
    "WHERE a.station_name='{0}';\n",
    "DROP INDEX IF EXISTS subdivided_idx;\n",
    "CREATE INDEX subdivided_idx ON subdivided USING GIST(geom);\n",
    "DROP TABLE IF EXISTS slopeData;\n",
    "CREATE TEMP TABLE slopeData AS \n",
    "SELECT ST_DumpAsPolygons(rast) AS geo \n",
    "FROM test.resultsshp AS a, svalbard.slope as b \n",
    "WHERE ST_Intersects(b.extent,a.basin) \n",
    "AND a.station_name='{0}';\n",
    "DROP INDEX IF EXISTS slopeData_idx;\n",
    "CREATE INDEX slopeData_idx ON slopeData USING GIST(((slopeData.geo).geom));\n",
    "CREATE TEMP TABLE {0}(id SERIAL PRIMARY KEY, slope DOUBLE PRECISION, geom GEOMETRY(POLYGON,3035));\n",
    "INSERT INTO {0}(slope,geom)\n",
    "SELECT DISTINCT (a.geo).val, (a.geo).geom \n",
    "FROM slopeData AS a, subdivided AS b \n",
    "WHERE ST_Intersects(b.geom,(a.geo).geom);\n",
    "CREATE TEMP TABLE toRemove(id INTEGER, geom GEOMETRY(POLYGON,3035));\n",
    "WITH myLine AS (SELECT ST_Boundary(basin) AS geom FROM test.resultsshp AS a WHERE a.station_name='{0}') \n",
    "                  INSERT INTO toRemove(id,geom)\n",
    "                  SELECT a.id,a.geom \n",
    "                  FROM {0} AS a, myLine AS b\n",
    "                  WHERE ST_Intersects(a.geom,b.geom);\n",
    "CREATE TEMP TABLE intersections AS\n",
    "SELECT a.id, SUM(ST_Area(ST_Intersection(a.geom,b.geom))) AS suma\n",
    "                 FROM subdivided AS b, toRemove AS a\n",
    "                 WHERE ST_Intersects(a.geom,b.geom)\n",
    "                 GROUP by a.id;\n",
    "DELETE FROM {0} AS a USING intersections AS b WHERE a.id=b.id AND b.suma < 0.1;\n",
    "SELECT slope,st_area(geom) FROM {0};\n",
    "'''\n",
    "cnt = 0\n",
    "for i in stations:\n",
    "    display(i)\n",
    "    data = query(queryStr.format(i))\n",
    "    dummy = pd.DataFrame({i : [j[0] for j in data]}).describe()\n",
    "    if cnt == 0:\n",
    "        result = dummy;\n",
    "    else :\n",
    "        result = pd.concat([result, dummy], axis=1, join='inner')\n",
    "    cnt=cnt+1\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('slope_in_degrees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
